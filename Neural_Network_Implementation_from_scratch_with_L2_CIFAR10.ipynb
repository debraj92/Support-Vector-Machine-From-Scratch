{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Network_Implementation_from_scratch_with_L2_CIFAR10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Data** **Preparation**"
      ],
      "metadata": {
        "id": "cF5zCrVl4LuY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcyoXPch4KlY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import gzip\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "import sklearn\n",
        "import sklearn.datasets\n",
        "import scipy\n",
        "from PIL import Image\n",
        "from scipy import ndimage\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def load_data():\n",
        "#   '''\n",
        "#   Reads the .pkl file and loads data into variables\n",
        "#   '''\n",
        "#   f = gzip.open('mnist.pkl.gz', 'rb')\n",
        "#   f.seek(0)\n",
        "#   training_data, validation_data, test_data = pickle.load(f, encoding='latin1')\n",
        "#   f.close()\n",
        "#   return (training_data, validation_data, test_data)"
      ],
      "metadata": {
        "id": "YVi1OffT4RzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cifar10_load_data():\n",
        "  (trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "  return trainX, trainY, testX, testY"
      ],
      "metadata": {
        "id": "Q94MIy2Dftuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainX, trainY, testX, testY = cifar10_load_data()\n",
        "\n",
        "training_data = []\n",
        "test_data = []\n",
        "\n",
        "training_data.append(trainX)\n",
        "training_data.append(trainY)\n",
        "\n",
        "test_data.append(testX)\n",
        "test_data.append(testY)"
      ],
      "metadata": {
        "id": "dSYPP4pcg-Ha",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e713b141-46f0-422a-efce-4df530f59b43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data[0] = training_data[0].reshape(training_data[0].shape[0], training_data[0].shape[1]*training_data[0].shape[2]*training_data[0].shape[3])"
      ],
      "metadata": {
        "id": "HZOgnA57hFRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data[1] = training_data[1].reshape(training_data[1].shape[0], )"
      ],
      "metadata": {
        "id": "bLM9-xo_hFU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data[1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpAFriOX4WHD",
        "outputId": "dab22cf8-9f61-46e3-d3f0-b03bf22e6041"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000,)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input and target label shapes\n",
        "print(training_data[0].shape)\n",
        "print(training_data[1].shape)\n",
        "print(test_data[0].shape)\n",
        "print(test_data[1].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWwaNshU4WJ8",
        "outputId": "8236698d-5739-4505-d33a-ff7cd219ecc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 3072)\n",
            "(50000,)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The feature dataset is:\" + str(training_data[0]))\n",
        "print(\"The target dataset is:\" + str(training_data[1]))\n",
        "print(\"The number of examples in the training dataset is:\" + str(len(training_data[0])))\n",
        "print(\"The number of points in a single input is:\" + str(len(training_data[0][1])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmAaAclG4WM4",
        "outputId": "807ed313-d261-4e0a-abdf-c5bc8b5e21a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The feature dataset is:[[ 59  62  63 ... 123  92  72]\n",
            " [154 177 187 ... 143 133 144]\n",
            " [255 255 255 ...  80  86  84]\n",
            " ...\n",
            " [ 35 178 235 ...  12  31  50]\n",
            " [189 211 240 ... 195 190 171]\n",
            " [229 229 239 ... 163 163 161]]\n",
            "The target dataset is:[6 9 9 ... 9 1 1]\n",
            "The number of examples in the training dataset is:50000\n",
            "The number of points in a single input is:3072\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **One-Hot Representation**"
      ],
      "metadata": {
        "id": "C12PJ8Td4leN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot(j):\n",
        "  '''\n",
        "  Input: List of m labels\n",
        "  Output: Returns (10, m) matrix with one-hot representation\n",
        "  '''\n",
        "  n = j.shape[0]\n",
        "  new_array = np.zeros((10, n))\n",
        "  index = 0\n",
        "  for res in j:\n",
        "      new_array[res][index] = 1.0\n",
        "      index = index + 1\n",
        "  return new_array"
      ],
      "metadata": {
        "id": "zyGOvvye4WPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_wrapper():\n",
        "    '''\n",
        "    Converts the dataset into desired shape and also converts the ground truth to one-hot representation\n",
        "    '''\n",
        "    trainX, trainY, testX, testY = cifar10_load_data()\n",
        "\n",
        "    training_data = []\n",
        "    test_data = []\n",
        "\n",
        "    training_data.append(trainX)\n",
        "    training_data.append(trainY)\n",
        "\n",
        "    test_data.append(testX)\n",
        "    test_data.append(testY)\n",
        "\n",
        "    training_data[0] = training_data[0].reshape(training_data[0].shape[0], training_data[0].shape[1]*training_data[0].shape[2]*training_data[0].shape[3])\n",
        "    training_data[1] = training_data[1].reshape(training_data[1].shape[0], )\n",
        "\n",
        "    test_data[0] = test_data[0].reshape(test_data[0].shape[0], test_data[0].shape[1]*test_data[0].shape[2]*test_data[0].shape[3])\n",
        "    test_data[1] = test_data[1].reshape(test_data[1].shape[0], )\n",
        "\n",
        "    training_inputs = np.array(training_data[0][:]).T\n",
        "    training_results = np.array(training_data[1][:])\n",
        "    train_set_y = one_hot(training_results)\n",
        "    \n",
        "    test_inputs = np.array(test_data[0][:]).T\n",
        "    test_results = np.array(test_data[1][:])\n",
        "    test_set_y = one_hot(test_results)\n",
        "    \n",
        "    return (training_inputs, train_set_y, test_inputs, test_set_y)"
      ],
      "metadata": {
        "id": "XSMmVG0T4WSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set_x, train_set_y, test_set_x, test_set_y = data_wrapper()"
      ],
      "metadata": {
        "id": "37OOVcGVBpcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"train_set_x shape: \" + str(train_set_x.shape))\n",
        "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
        "print (\"test_set_x shape: \" + str(test_set_x.shape))\n",
        "print (\"test_set_y shape: \" + str(test_set_y.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iS8fJv8PBpfA",
        "outputId": "3755e786-dba9-4d3c-b6f9-334a21340147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_set_x shape: (3072, 50000)\n",
            "train_set_y shape: (10, 50000)\n",
            "test_set_x shape: (3072, 10000)\n",
            "test_set_y shape: (10, 10000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting labels into dataframe.\n",
        "y = pd.DataFrame(train_set_y)"
      ],
      "metadata": {
        "id": "jMaI0zzFBph7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The target dataset is:\" + str(training_data[1]))\n",
        "print(\"The one hot encoding dataset is:\")\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "id": "3G_Ye_70BzGR",
        "outputId": "d1d04dc5-c0d1-47a0-bfb7-d6ac9a9bc2b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The target dataset is:[6 9 9 ... 9 1 1]\n",
            "The one hot encoding dataset is:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0      1      2      3      4      5      6      7      8      9      ...  \\\n",
              "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
              "1    0.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    0.0  ...   \n",
              "2    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0  ...   \n",
              "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0  ...   \n",
              "4    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
              "5    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
              "6    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
              "7    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0  ...   \n",
              "8    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0  ...   \n",
              "9    0.0    1.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
              "\n",
              "   49990  49991  49992  49993  49994  49995  49996  49997  49998  49999  \n",
              "0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0  \n",
              "1    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    1.0    1.0  \n",
              "2    0.0    1.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0  \n",
              "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
              "4    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
              "5    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
              "6    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0  \n",
              "7    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
              "8    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
              "9    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0  \n",
              "\n",
              "[10 rows x 50000 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2d74c1c0-12c3-4409-916a-4b4e0c5af0ba\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>49990</th>\n",
              "      <th>49991</th>\n",
              "      <th>49992</th>\n",
              "      <th>49993</th>\n",
              "      <th>49994</th>\n",
              "      <th>49995</th>\n",
              "      <th>49996</th>\n",
              "      <th>49997</th>\n",
              "      <th>49998</th>\n",
              "      <th>49999</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows Ã— 50000 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d74c1c0-12c3-4409-916a-4b4e0c5af0ba')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2d74c1c0-12c3-4409-916a-4b4e0c5af0ba button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2d74c1c0-12c3-4409-916a-4b4e0c5af0ba');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The feature dataset is:\" + str(training_data[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8q3EOr5nS3w",
        "outputId": "eb44f960-9e0c-47ca-ac3b-802c922335cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The feature dataset is:[[ 59  62  63 ... 123  92  72]\n",
            " [154 177 187 ... 143 133 144]\n",
            " [255 255 255 ...  80  86  84]\n",
            " ...\n",
            " [ 35 178 235 ...  12  31  50]\n",
            " [189 211 240 ... 195 190 171]\n",
            " [229 229 239 ... 163 163 161]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The feature dataset is:\" + str(train_set_x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtuqLOqynnnv",
        "outputId": "ced526c7-fcd4-4c59-eda6-b63d8563704d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The feature dataset is:[[ 59 154 255 ...  35 189 229]\n",
            " [ 62 177 255 ... 178 211 229]\n",
            " [ 63 187 255 ... 235 240 239]\n",
            " ...\n",
            " [123 143  80 ...  12 195 163]\n",
            " [ 92 133  86 ...  31 190 163]\n",
            " [ 72 144  84 ...  50 171 161]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Visualizing Sample Training Input Image**"
      ],
      "metadata": {
        "id": "cIbT4dfmifrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index  = 1001\n",
        "k = train_set_x[:,index]\n",
        "k = k.reshape((32, 32, 3))\n",
        "plt.title('Label is {label}'.format(label= training_data[1][index]))\n",
        "plt.imshow(k, cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "zyIQv47VBzI0",
        "outputId": "80125df3-6024-498f-e8d5-86154923a3c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7faf7c5b50d0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Normalizing Input Features**"
      ],
      "metadata": {
        "id": "T3TmLnrBiR6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_input_features(x_data):\n",
        "  '''\n",
        "  Input: x_data - value range (0, 255)\n",
        "  Output: x_data - value range (0, 1)\n",
        "  '''\n",
        "  #Divide all the features with 255(pixel value range)\n",
        "  x_data = x_data/255.0\n",
        "  return x_data"
      ],
      "metadata": {
        "id": "vUlqlvj1iRSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set_x = normalize_input_features(train_set_x)\n",
        "test_set_x = normalize_input_features(test_set_x)"
      ],
      "metadata": {
        "id": "BziD0PjtiM_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Feedforward**"
      ],
      "metadata": {
        "id": "nwhc0NPuCNDc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Activation Functions"
      ],
      "metadata": {
        "id": "66JFBL4NCbFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(Z):\n",
        "  '''\n",
        "  Input: Z is the cummulation input to the layer\n",
        "  Output: Returns  sigmoid activation H matrix, sigmoid_memory later used in the backpropogation.\n",
        "  '''\n",
        "   \n",
        "  H = 1/(1+np.exp(-Z))\n",
        "  sigmoid_memory = Z\n",
        "  \n",
        "  return H, sigmoid_memory"
      ],
      "metadata": {
        "id": "rNopgScSCMUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Z = np.arange(8).reshape(4,2)\n",
        "print (\"sigmoid(Z) = \" + str(sigmoid(Z)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14t4kydxHkF2",
        "outputId": "c5ce2fa3-fc86-4089-d5a0-d5e301bca97c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sigmoid(Z) = (array([[0.5       , 0.73105858],\n",
            "       [0.88079708, 0.95257413],\n",
            "       [0.98201379, 0.99330715],\n",
            "       [0.99752738, 0.99908895]]), array([[0, 1],\n",
            "       [2, 3],\n",
            "       [4, 5],\n",
            "       [6, 7]]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(Z):\n",
        "  '''\n",
        "  Input: Z is the cummulation input to the layer\n",
        "  Output: Returns relu activation H matrix, relu_memory later used in the backpropogation.\n",
        "  '''\n",
        "\n",
        "  H = np.maximum(0,Z)\n",
        "  assert(H.shape == Z.shape)\n",
        "  \n",
        "  relu_memory = Z \n",
        "  return H, relu_memory"
      ],
      "metadata": {
        "id": "JxxEpArPBzMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Z = np.array([1, 3, -1, -4, -5, 7, 9, 18]).reshape(4,2)\n",
        "print (\"relu(Z) = \" + str(relu(Z)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3Rzx8XSHkfj",
        "outputId": "22a666db-45c4-4df2-8ea6-062ca5e04eef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "relu(Z) = (array([[ 1,  3],\n",
            "       [ 0,  0],\n",
            "       [ 0,  7],\n",
            "       [ 9, 18]]), array([[ 1,  3],\n",
            "       [-1, -4],\n",
            "       [-5,  7],\n",
            "       [ 9, 18]]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(Z):\n",
        "  '''\n",
        "  Input: Z is the cummulation input to the layer\n",
        "  Output: Returns softmax activation H matrix, softmax_memory later used in the backpropogation.\n",
        "  '''\n",
        "  Z_exp = np.exp(Z)\n",
        "\n",
        "  Z_sum = np.sum(Z_exp,axis = 0, keepdims = True)\n",
        "  \n",
        "  H = Z_exp/Z_sum  #normalising step\n",
        "  softmax_memory = Z\n",
        "  \n",
        "  return H, softmax_memory"
      ],
      "metadata": {
        "id": "DFb31iYPBzQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Z = np.array([[11,19,10], [12, 21, 23]])\n",
        "H, softmax_memory = softmax(Z)\n",
        "print(H)\n",
        "print(softmax_memory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrnzMOlZHlBu",
        "outputId": "34f505e3-bec8-4f39-dcde-215ba5259998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.68941421e-01 1.19202922e-01 2.26032430e-06]\n",
            " [7.31058579e-01 8.80797078e-01 9.99997740e-01]]\n",
            "[[11 19 10]\n",
            " [12 21 23]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Initializing Parameters**"
      ],
      "metadata": {
        "id": "WfHRa_0XG1TP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_parameters(dimensions):\n",
        "  '''\n",
        "  Input: dimensions is a list containing the number of neuron in each layer in the network\n",
        "  Output: Returns parameters which is a python dictionary containing the parameters \"W1\", \"b1\", ..., \"WL\", \"bL\"\n",
        "  '''\n",
        "  np.random.seed(2)\n",
        "  parameters = {}\n",
        "  L = len(dimensions)            # number of layers in the network + 1\n",
        "\n",
        "  for l in range(1, L): \n",
        "      parameters['W' + str(l)] = np.random.randn(dimensions[l], dimensions[l-1]) * 0.1\n",
        "      parameters['b' + str(l)] = np.zeros((dimensions[l], 1)) \n",
        "      \n",
        "      assert(parameters['W' + str(l)].shape == (dimensions[l], dimensions[l-1]))\n",
        "      assert(parameters['b' + str(l)].shape == (dimensions[l], 1))\n",
        "\n",
        "  return parameters"
      ],
      "metadata": {
        "id": "8ZtECxcVBzUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dimensions  = [3072, 50,30,10]\n",
        "parameters = initialize_parameters(dimensions)\n",
        "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
        "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
        "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
        "print(\"b2 = \" + str(parameters[\"b2\"]))\n",
        "# print(\"W3 = \" + str(parameters[\"W3\"]))\n",
        "# print(\"b3 = \" + str(parameters[\"b3\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWeJPMJELPaF",
        "outputId": "c67c40fb-5f48-42b9-f4c7-7b8606de08b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W1 = [[-0.04167578 -0.00562668 -0.21361961 ...  0.1524183   0.08030679\n",
            "  -0.20630668]\n",
            " [-0.09200544 -0.13593063  0.08496996 ... -0.12692491  0.07624151\n",
            "  -0.04693156]\n",
            " [-0.06137873 -0.05361845  0.02268961 ...  0.10159502 -0.00699543\n",
            "  -0.06247429]\n",
            " ...\n",
            " [ 0.00910123  0.02439772 -0.13233185 ...  0.07503009 -0.13448223\n",
            "  -0.07157332]\n",
            " [ 0.09261     0.17766335  0.03598191 ... -0.15794373  0.02094899\n",
            "   0.13354639]\n",
            " [ 0.16270249  0.04882228  0.09768919 ...  0.11005103  0.07527573\n",
            "  -0.03201027]]\n",
            "b1 = [[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n",
            "W2 = [[ 0.07274892 -0.12431079  0.09388836 ...  0.04232581 -0.03809435\n",
            "   0.04695959]\n",
            " [ 0.01355018 -0.00410413  0.05861805 ... -0.0926292   0.03019752\n",
            "   0.17926195]\n",
            " [ 0.06057359 -0.10183213  0.0349793  ... -0.01907301 -0.04194475\n",
            "  -0.03126343]\n",
            " ...\n",
            " [-0.12049108 -0.04279057 -0.06390614 ...  0.08676161  0.00970101\n",
            "   0.08503978]\n",
            " [ 0.01365067  0.0382157  -0.04103964 ...  0.11488361 -0.03816836\n",
            "  -0.09411816]\n",
            " [-0.03064999 -0.23264295 -0.09153582 ...  0.18147381  0.04753706\n",
            "  -0.0181576 ]]\n",
            "b2 = [[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Forward Pass**"
      ],
      "metadata": {
        "id": "bhb-imHOHYKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This performs one forward propogation for a certain layer 'l'\n",
        "def layer_forward(H_prev, W, b, activation = 'relu'): \n",
        "  '''\n",
        "  Input: H_prev this is the input cummulative to the current layer, W is weights matrix of shape\n",
        "  b is bias vector of shape, activation to be used for forward propagation : \"softmax\", \"relu\", \"sigmoid\"\n",
        "  Output: Returns H is the output of the activation function, memory is a python dictionary containing linear or activation memory.\n",
        "  '''\n",
        "  \n",
        "  Z = np.dot(W, H_prev) + b\n",
        "  if activation == \"sigmoid\":\n",
        "      linear_memory = (H_prev, W, b)\n",
        "      H, activation_memory = sigmoid(Z)\n",
        "\n",
        "  elif activation == \"softmax\":\n",
        "      linear_memory = (H_prev, W, b)\n",
        "      H, activation_memory = softmax(Z)\n",
        "  \n",
        "  elif activation == \"relu\":\n",
        "      linear_memory = (H_prev, W, b)\n",
        "      H, activation_memory = relu(Z)\n",
        "      \n",
        "  assert (H.shape == (W.shape[0], H_prev.shape[1]))\n",
        "  memory = (linear_memory, activation_memory)\n",
        "\n",
        "  return H, memory"
      ],
      "metadata": {
        "id": "BbSs_goKBzXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "H_prev = np.array([[1,0, 5, 10, 2], [2, 5, 3, 10, 2]])\n",
        "W_sample = np.array([[10, 5], [2, 0], [1, 0]])\n",
        "b_sample = np.array([10, 5, 0]).reshape((3, 1))\n",
        "\n",
        "H = layer_forward(H_prev, W_sample, b_sample, activation=\"sigmoid\")[0]\n",
        "H"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1x68q1AoBzaW",
        "outputId": "cc940c0c-714b-40fc-b006-8b797906ce96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 1.        , 1.        , 1.        , 1.        ],\n",
              "       [0.99908895, 0.99330715, 0.99999969, 1.        , 0.99987661],\n",
              "       [0.73105858, 0.5       , 0.99330715, 0.9999546 , 0.88079708]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This performs one forward pass through the whole network for all training samples.\n",
        "\n",
        "def L_layer_forward(X, parameters):\n",
        "  '''\n",
        "  Input: X is input data, parameters is output of initialize_parameters()\n",
        "  Output: HL is the last layer's post-activation value, memories is the list of memory containing \n",
        "  -every memory of relu forward (there are L-1 of them, indexed from 1 to L-1), \n",
        "  - the memory of softmax forward (there is one, indexed L)\n",
        "  '''\n",
        "\n",
        "  memories = []\n",
        "  H = X\n",
        "  L = len(parameters) // 2   # number of layers in the neural network\n",
        "  \n",
        "  for l in range(1, L):\n",
        "      H_prev = H\n",
        "      W=parameters[\"W\"+str(l)]\n",
        "      b=parameters[\"b\"+str(l)]\n",
        "      H, memory = layer_forward(H_prev, W, b, activation = 'relu')\n",
        "      \n",
        "      memories.append(memory)\n",
        "  # HL here is the final prediction in the final layer.\n",
        "  W=parameters[\"W\"+str(L)]\n",
        "  b=parameters[\"b\"+str(L)]\n",
        "  HL, memory = layer_forward(H, W, b, activation = 'softmax')\n",
        "  \n",
        "  memories.append(memory)\n",
        "\n",
        "  assert(HL.shape == (10, X.shape[1]))\n",
        "          \n",
        "  return HL, memories"
      ],
      "metadata": {
        "id": "_SNkOeisHjOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# verify\n",
        "# X is (784, 10)\n",
        "# HL should be (10, 10)\n",
        "x_sample = train_set_x[:, 10:20]\n",
        "print(x_sample.shape)\n",
        "HL = L_layer_forward(x_sample, parameters=parameters)[0]\n",
        "print(HL[:, :5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9Vo4uRhYfNz",
        "outputId": "0f434ae6-3e0b-4b12-a90f-7d3f0703eee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3072, 10)\n",
            "[[0.09603292 0.10332619 0.10072717 0.07984978 0.10220821]\n",
            " [0.11620353 0.10448309 0.10901814 0.12356772 0.10530881]\n",
            " [0.07614087 0.09424911 0.08542518 0.09570283 0.1034351 ]\n",
            " [0.08101748 0.07600863 0.08355484 0.09247589 0.09361884]\n",
            " [0.1128413  0.12218834 0.15372606 0.08737461 0.13366497]\n",
            " [0.05319072 0.03153383 0.04709441 0.05959022 0.04991382]\n",
            " [0.15533599 0.19629798 0.13566798 0.1358282  0.12485884]\n",
            " [0.1213836  0.08843032 0.10278885 0.13194721 0.1073737 ]\n",
            " [0.07710091 0.05984595 0.0572367  0.07929129 0.07555153]\n",
            " [0.11075267 0.12363657 0.12476067 0.11437224 0.10406617]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Loss**"
      ],
      "metadata": {
        "id": "0eWUZjRLYj0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross entropy loss\n",
        "def compute_loss(HL, Y):\n",
        "  '''\n",
        "  Input: HL is the output probability from the network, Y is the true labels\n",
        "  Output: Cross-entropy loss\n",
        "  '''\n",
        "  m = Y.shape[1]\n",
        "  loss = -(1./m)*np.sum(np.multiply(Y,np.log(HL)))\n",
        "  \n",
        "  loss = np.squeeze(loss) # To make sure that the loss's shape is what we expect (e.g. this turns [[17]] into 17).\n",
        "  assert(loss.shape == ())\n",
        "  \n",
        "  return loss"
      ],
      "metadata": {
        "id": "zmphsLWiYfQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample\n",
        "\n",
        "np.random.seed(2)\n",
        "HL_sample = np.random.rand(10,5)\n",
        "Y_sample = train_set_y[:, 10:15]\n",
        "print(HL_sample)\n",
        "print(Y_sample)\n",
        "\n",
        "print(compute_loss(HL_sample, Y_sample))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1Z-mE6nYfU3",
        "outputId": "a9676c2d-9b22-4128-df61-b2a0f8fe4893"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.4359949  0.02592623 0.54966248 0.43532239 0.4203678 ]\n",
            " [0.33033482 0.20464863 0.61927097 0.29965467 0.26682728]\n",
            " [0.62113383 0.52914209 0.13457995 0.51357812 0.18443987]\n",
            " [0.78533515 0.85397529 0.49423684 0.84656149 0.07964548]\n",
            " [0.50524609 0.0652865  0.42812233 0.09653092 0.12715997]\n",
            " [0.59674531 0.226012   0.10694568 0.22030621 0.34982629]\n",
            " [0.46778748 0.20174323 0.64040673 0.48306984 0.50523672]\n",
            " [0.38689265 0.79363745 0.58000418 0.1622986  0.70075235]\n",
            " [0.96455108 0.50000836 0.88952006 0.34161365 0.56714413]\n",
            " [0.42754596 0.43674726 0.77655918 0.53560417 0.95374223]]\n",
            "[[0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 1. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]]\n",
            "0.4344546265898296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross entropy loss with L2 regularization\n",
        "def compute_loss_with_L2(HL, Y, parameters, lambdax):\n",
        "  '''\n",
        "  Input: HL is the output probability from the network, Y is the true labels\n",
        "  Output: Cross-entropy loss\n",
        "  '''\n",
        "\n",
        "  L = len(parameters) // 2   # Number of layers\n",
        "\n",
        "  m = Y.shape[1]\n",
        "  loss = -(1./m)*np.sum(np.multiply(Y,np.log(HL)))\n",
        "  total_sum  =0\n",
        "  for l in range(1, L):\n",
        "    total_sum += np.sum(np.square(parameters[\"W\"+str(l)]))\n",
        "  L2_regularization_cost = (lambdax/(2*m))*total_sum\n",
        "  # L2_regularization_cost = (lambdax/(2*m))*(np.sum(np.square(W1) + np.sum(np.square(W2) + np.sum(np.square(W2)))\n",
        "  # print(\"L2 loss before \", L2_regularization_cost)\n",
        "  loss = loss + L2_regularization_cost\n",
        "  loss = np.squeeze(loss) # To make sure that the loss's shape is what we expect (e.g. this turns [[17]] into 17).\n",
        "  assert(loss.shape == ())\n",
        "  \n",
        "  return loss"
      ],
      "metadata": {
        "id": "XQCXS59cT5Dn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample\n",
        "\n",
        "np.random.seed(2)\n",
        "HL_sample = np.random.rand(10,5)\n",
        "Y_sample = train_set_y[:, 10:15]\n",
        "print(HL_sample)\n",
        "print(Y_sample)\n",
        "\n",
        "print(compute_loss_with_L2(HL_sample, Y_sample, parameters, 0.7))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9bf3B_wXRvt",
        "outputId": "bd1d7593-bb02-4fbb-9b85-c1ca1e2002c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.4359949  0.02592623 0.54966248 0.43532239 0.4203678 ]\n",
            " [0.33033482 0.20464863 0.61927097 0.29965467 0.26682728]\n",
            " [0.62113383 0.52914209 0.13457995 0.51357812 0.18443987]\n",
            " [0.78533515 0.85397529 0.49423684 0.84656149 0.07964548]\n",
            " [0.50524609 0.0652865  0.42812233 0.09653092 0.12715997]\n",
            " [0.59674531 0.226012   0.10694568 0.22030621 0.34982629]\n",
            " [0.46778748 0.20174323 0.64040673 0.48306984 0.50523672]\n",
            " [0.38689265 0.79363745 0.58000418 0.1622986  0.70075235]\n",
            " [0.96455108 0.50000836 0.88952006 0.34161365 0.56714413]\n",
            " [0.42754596 0.43674726 0.77655918 0.53560417 0.95374223]]\n",
            "[[0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 1. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]]\n",
            "108.78471741951715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **BackPropogation**"
      ],
      "metadata": {
        "id": "WTGEldWbZj-J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **sigmoid-backward & relu-backward**"
      ],
      "metadata": {
        "id": "IMV7ICtEaCeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Backpropogation fo the sigmoid function\n",
        "def sigmoid_backward(dH, sigmoid_memory):\n",
        "  '''\n",
        "  Input: dH is gradient of the sigmoid activated activation of shape same as H or Z in the same layer,\n",
        "  sigmoid_memory is the memory stored in the sigmoid(Z) calculation.\n",
        "  Output: Returns derivate of Loss w.r.t Z\n",
        "  '''\n",
        "  # sigmoid_memory is the memory stored in the sigmoid(Z) calculation\n",
        "  \n",
        "  Z = sigmoid_memory\n",
        "  \n",
        "  H = 1/(1+np.exp(-Z))\n",
        "  dZ = dH * H * (1-H)\n",
        "  \n",
        "  assert (dZ.shape == Z.shape)\n",
        "  \n",
        "  return dZ"
      ],
      "metadata": {
        "id": "adriZS-lZgq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Backpropogation fo the sigmoid function\n",
        "def relu_backward(dH, relu_memory):\n",
        "  '''\n",
        "  Input: dH is gradient of the relu activated activation of shape same as H or Z in the same layer,\n",
        "  relu_memory is the memory stored in the relu(Z) calculation.\n",
        "  Output: Returns derivate of Loss w.r.t Z\n",
        "  '''\n",
        "\n",
        "  Z = relu_memory\n",
        "  dZ = np.array(dH, copy=True) # dZ will be the same as dA wherever the elements of A weren't 0\n",
        "  \n",
        "  dZ[Z <= 0] = 0\n",
        "  \n",
        "  assert (dZ.shape == Z.shape)\n",
        "  \n",
        "  return dZ"
      ],
      "metadata": {
        "id": "iYrECScpZgvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def layer_backward(dH, memory, activation = 'relu'):\n",
        "  '''\n",
        "  Input: takes dH and the memory calculated in layer_forward and activation\n",
        "  Output: Returns to calculate the dH_prev, dW, db\n",
        "  '''\n",
        "\n",
        "\n",
        "  linear_memory, activation_memory = memory\n",
        "  \n",
        "  if activation == \"relu\":\n",
        "      dZ = relu_backward(dH,activation_memory)\n",
        "      H_prev, W, b = linear_memory\n",
        "      m = H_prev.shape[1]\n",
        "      dW = (1./m) * np.dot(dZ,H_prev.transpose())\n",
        "      db = (1./m) * np.sum(dZ,axis=1)\n",
        "      db = np.reshape(db,(-1, 1))\n",
        "      dH_prev = np.dot(W.transpose(),dZ)\n",
        "      \n",
        "  elif activation == \"sigmoid\":\n",
        "      dZ = sigmoid_backward(dH, activation_memory)\n",
        "      H_prev, W, b = linear_memory\n",
        "      m = H_prev.shape[1]\n",
        "      dW = (1./m) * np.dot(dZ,H_prev.transpose())\n",
        "      db = (1./m) * np.sum(dZ,axis=1)\n",
        "      db = np.reshape(db,(-1, 1))\n",
        "      dH_prev = np.dot(W.transpose(),dZ)\n",
        "  \n",
        "  return dH_prev, dW, db"
      ],
      "metadata": {
        "id": "n5_7-1sFZgx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "H_prev = np.array([[1,0, 5, 10, 2], [2, 5, 3, 10, 2]])\n",
        "W_sample = np.array([[10, 5], [2, 0], [1, 0]])\n",
        "b_sample = np.array([10, 5, 0]).reshape((3, 1))\n",
        "\n",
        "H, memory = layer_forward(H_prev, W_sample, b_sample, activation=\"relu\")\n",
        "np.random.seed(2)\n",
        "dH = np.random.rand(3,5)\n",
        "dH_prev, dW, db = layer_backward(dH, memory, activation = 'relu')\n",
        "print('dH_prev is \\n' , dH_prev)\n",
        "print('dW is \\n' ,dW)\n",
        "print('db is \\n', db)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19uUnRgReOz3",
        "outputId": "ffde92b8-d3bf-4dfe-b543-3abdc02e4cc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dH_prev is \n",
            " [[5.6417525  0.66855959 6.86974666 5.46611139 4.92177244]\n",
            " [2.17997451 0.12963116 2.74831239 2.17661196 2.10183901]]\n",
            "dW is \n",
            " [[1.67565336 1.56891359]\n",
            " [1.39137819 1.4143854 ]\n",
            " [1.3597389  1.43013369]]\n",
            "db is \n",
            " [[0.37345476]\n",
            " [0.34414727]\n",
            " [0.29074635]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def L_layer_backward(HL, Y, memories):\n",
        "  '''\n",
        "  Input: predicted value HL and the true target value Y and memories calculated by L_layer_forward\n",
        "  Output: Returns gradient.\n",
        "  '''\n",
        "\n",
        "  gradients = {}\n",
        "  L = len(memories) # the number of layers\n",
        "  m = HL.shape[1]\n",
        "  Y = Y.reshape(HL.shape) # after this line, Y is the same shape as AL\n",
        "  \n",
        "  # Perform the backprop for the last layer that is the softmax layer\n",
        "  current_memory = memories[-1]\n",
        "  linear_memory, activation_memory = current_memory\n",
        "  dZ = HL - Y\n",
        "  H_prev, W, b = linear_memory\n",
        "  \n",
        "  gradients[\"dH\" + str(L-1)] = np.dot(W.transpose(),dZ)\n",
        "  gradients[\"dW\" + str(L)] = (1./m) * np.dot(dZ,H_prev.transpose())\n",
        "  db = (1./m) * np.sum(dZ,axis=1)\n",
        "  db = np.reshape(db,(-1, 1))\n",
        "  gradients[\"db\" + str(L)] = db\n",
        "  \n",
        "  # Perform the backpropagation l-1 times\n",
        "  for l in reversed(range(L-1)):\n",
        "      # Lth layer gradients: \"gradients[\"dH\" + str(l + 1)] \", gradients[\"dW\" + str(l + 2)] , gradients[\"db\" + str(l + 2)]\n",
        "      current_memory = memories[l]\n",
        "      \n",
        "      dH_prev_temp, dW_temp, db_temp = layer_backward(gradients[\"dH\" + str(l + 1)], current_memory, activation = 'relu')\n",
        "      gradients[\"dH\" + str(l)] = dH_prev_temp\n",
        "      gradients[\"dW\" + str(l + 1)] = dW_temp\n",
        "      gradients[\"db\" + str(l + 1)] = db_temp\n",
        "\n",
        "\n",
        "  return gradients"
      ],
      "metadata": {
        "id": "OR5gNsOnYfWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def L_layer_backward_with_L2(HL, Y, memories, lambdax):\n",
        "  '''\n",
        "  Input: predicted value HL and the true target value Y and memories calculated by L_layer_forward\n",
        "  Output: Returns gradient.\n",
        "  '''\n",
        "\n",
        "  gradients = {}\n",
        "  L = len(memories) # the number of layers\n",
        "  m = HL.shape[1]\n",
        "  Y = Y.reshape(HL.shape) # after this line, Y is the same shape as AL\n",
        "  \n",
        "  # Perform the backprop for the last layer that is the softmax layer\n",
        "  current_memory = memories[-1]\n",
        "  linear_memory, activation_memory = current_memory\n",
        "  dZ = HL - Y\n",
        "  H_prev, W, b = linear_memory\n",
        "  \n",
        "  gradients[\"dH\" + str(L-1)] = np.dot(W.transpose(),dZ)\n",
        "  gradients[\"dW\" + str(L)] = (1./m) * np.dot(dZ,H_prev.transpose())\n",
        "  gradients[\"dW\" + str(L)] += (lambdax * gradients[\"dW\" + str(L)])/m\n",
        "  db = (1./m) * np.sum(dZ,axis=1)\n",
        "  db = np.reshape(db,(-1, 1))\n",
        "  gradients[\"db\" + str(L)] = db\n",
        "  \n",
        "  # Perform the backpropagation l-1 times\n",
        "  for l in reversed(range(L-1)):\n",
        "      # Lth layer gradients: \"gradients[\"dH\" + str(l + 1)] \", gradients[\"dW\" + str(l + 2)] , gradients[\"db\" + str(l + 2)]\n",
        "      current_memory = memories[l]\n",
        "      \n",
        "      dH_prev_temp, dW_temp, db_temp = layer_backward(gradients[\"dH\" + str(l + 1)], current_memory, activation = 'relu')\n",
        "      gradients[\"dH\" + str(l)] = dH_prev_temp\n",
        "      gradients[\"dW\" + str(l + 1)] = dW_temp\n",
        "      # print(\"checking shape:\",(lambdax * gradients[\"dW\" + str(l+1)])/m)\n",
        "      gradients[\"dW\" + str(l + 1)] += (lambdax * gradients[\"dW\" + str(l+1)])/m\n",
        "      gradients[\"db\" + str(l + 1)] = db_temp\n",
        "\n",
        "\n",
        "  return gradients"
      ],
      "metadata": {
        "id": "hhtMhDSzZrWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_sample = train_set_x[:, 10:20]\n",
        "y_sample = train_set_y[:, 10:20]\n",
        "\n",
        "HL, memories = L_layer_forward(x_sample, parameters=parameters)\n",
        "gradients  = L_layer_backward_with_L2(HL, y_sample, memories, 0.7)\n",
        "print('dW3 is \\n', gradients['dW3'])\n",
        "print('db3 is \\n', gradients['db3'])\n",
        "print('dW2 is \\n', gradients['dW2'])\n",
        "print('db2 is \\n', gradients['db2'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5mVHSFreWEH",
        "outputId": "78739172-6f4f-4d2b-df1b-241647d84168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dW3 is \n",
            " [[ 3.26838694e-03  3.53796135e-02  1.11964913e-02  7.12537905e-02\n",
            "   0.00000000e+00  1.22712422e-01  9.58640125e-02  1.91825655e-02\n",
            "   5.37222446e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   1.38263246e-01  1.62425164e-01  0.00000000e+00  3.49007494e-02\n",
            "   9.93655201e-02  0.00000000e+00  2.52585993e-03  1.16855289e-02\n",
            "   0.00000000e+00  9.81397131e-04  0.00000000e+00  0.00000000e+00\n",
            "   1.83833483e-01  1.73286744e-02  3.38971900e-03  8.78729588e-02\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 5.79444294e-03  5.13772018e-02  1.42051425e-02  9.31570364e-02\n",
            "   0.00000000e+00  1.72466908e-01  1.24808962e-01  2.93073100e-02\n",
            "   7.46561262e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   2.02799548e-01  2.10212206e-01  0.00000000e+00  4.36488006e-02\n",
            "   1.34539774e-01  0.00000000e+00  3.90877421e-03  1.27782801e-02\n",
            "   0.00000000e+00  1.45606325e-03  0.00000000e+00  0.00000000e+00\n",
            "   2.33148176e-01  2.80986430e-02  5.24559817e-03  1.12892729e-01\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 3.62324709e-03 -7.15513875e-02  9.34063508e-03 -1.12840798e-01\n",
            "   0.00000000e+00 -4.60611605e-02 -9.02301396e-02 -4.40632523e-02\n",
            "  -5.52228214e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  -2.65493782e-01 -4.06202654e-02  0.00000000e+00 -8.56567338e-02\n",
            "  -8.28217149e-02  0.00000000e+00 -2.86053130e-02  8.77943379e-03\n",
            "   0.00000000e+00 -8.05042650e-03  0.00000000e+00  0.00000000e+00\n",
            "  -3.33518350e-02 -5.93679757e-02 -3.83884997e-02 -7.34319250e-02\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [-3.88753295e-02 -6.87659794e-02  8.72014945e-03  4.90421043e-02\n",
            "   0.00000000e+00 -6.50358092e-02  3.09898387e-02 -4.00323859e-02\n",
            "   3.40808660e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   1.88338023e-02  7.96240086e-02  0.00000000e+00  3.04462618e-02\n",
            "   6.98982394e-02  0.00000000e+00  2.92525727e-03  9.48895933e-03\n",
            "   0.00000000e+00  5.33928048e-04  0.00000000e+00  0.00000000e+00\n",
            "   1.35377524e-01 -6.18632713e-02  3.92571261e-03  6.48412734e-02\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 4.18488794e-03  1.31598985e-02  1.61565651e-02  8.53834425e-02\n",
            "   0.00000000e+00  1.09356653e-02  7.47417324e-02 -3.69307092e-02\n",
            "   4.18348514e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   5.96413461e-02  7.09981467e-02  0.00000000e+00 -6.08312585e-03\n",
            "   9.51192065e-02  0.00000000e+00  2.76389011e-03  1.77528156e-02\n",
            "   0.00000000e+00  9.04042876e-04  0.00000000e+00  0.00000000e+00\n",
            "   9.43553739e-02  1.99760453e-02  3.70915692e-03  1.06914108e-01\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 3.08235997e-03  2.13232072e-02  4.51037130e-03  2.61436626e-02\n",
            "   0.00000000e+00  5.85287475e-02  4.13555569e-02  1.23619578e-02\n",
            "   2.45055456e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   6.11571492e-02  6.80435486e-02  0.00000000e+00  1.65575658e-02\n",
            "   3.83858814e-02  0.00000000e+00  1.88499632e-03  4.81904347e-03\n",
            "   0.00000000e+00  3.29798645e-04  0.00000000e+00  0.00000000e+00\n",
            "   7.20323545e-02  1.11657517e-02  2.52967624e-03  3.44564022e-02\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 4.99443809e-03  3.05853964e-02  2.27543015e-02  3.28144501e-02\n",
            "   0.00000000e+00 -2.23589247e-03  8.96805198e-02 -1.26283560e-03\n",
            "  -2.56397769e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  -9.89756139e-02  3.70003478e-02  0.00000000e+00  4.22701613e-02\n",
            "  -4.49066888e-02  0.00000000e+00  4.29660544e-03  2.10569264e-02\n",
            "   0.00000000e+00  1.02120137e-03  0.00000000e+00  0.00000000e+00\n",
            "   7.37311879e-02  2.43229959e-02  5.76606998e-03  1.66398868e-02\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 5.52723394e-03 -7.39022559e-03  5.28889420e-03 -2.07978269e-01\n",
            "   0.00000000e+00 -1.33661906e-01 -2.35838347e-01  1.80011643e-02\n",
            "  -9.94354202e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  -7.35487072e-02 -2.59897844e-01  0.00000000e+00 -6.03555219e-02\n",
            "  -1.61458057e-01  0.00000000e+00  4.17383965e-03 -5.26346122e-02\n",
            "   0.00000000e+00  6.73035581e-04  0.00000000e+00  0.00000000e+00\n",
            "  -4.11785032e-01  2.14049175e-02  5.60131756e-03 -1.71603180e-01\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 3.57511572e-03  3.03742474e-02  7.08115800e-03  5.02090235e-02\n",
            "   0.00000000e+00  9.40441123e-02  6.88867480e-02  1.76035167e-02\n",
            "   4.06162610e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   1.10445303e-01  1.14846637e-01  0.00000000e+00  2.59731278e-02\n",
            "   7.17840263e-02  0.00000000e+00  2.50819331e-03  6.58496055e-03\n",
            "   0.00000000e+00  8.18313422e-04  0.00000000e+00  0.00000000e+00\n",
            "   1.27109509e-01  1.62462136e-02  3.36601030e-03  6.16491923e-02\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 4.82521690e-03 -3.44919723e-02 -9.92537084e-02 -8.71844424e-02\n",
            "   0.00000000e+00 -2.11693087e-01 -2.00258884e-01  2.58326688e-02\n",
            "  -8.91178763e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  -1.53122292e-01 -4.42631948e-01  0.00000000e+00 -4.17012852e-02\n",
            "  -2.19906187e-01  0.00000000e+00  3.61789675e-03 -4.03113359e-02\n",
            "   0.00000000e+00  1.33264617e-03  0.00000000e+00  0.00000000e+00\n",
            "  -4.74450741e-01 -1.73119943e-02  4.85523890e-03 -2.40231445e-01\n",
            "   0.00000000e+00  0.00000000e+00]]\n",
            "db3 is \n",
            " [[ 0.09272661]\n",
            " [ 0.12602329]\n",
            " [-0.10189551]\n",
            " [-0.02565951]\n",
            " [ 0.01570806]\n",
            " [ 0.04482153]\n",
            " [ 0.04356051]\n",
            " [-0.0908445 ]\n",
            " [ 0.07148138]\n",
            " [-0.17592186]]\n",
            "dW2 is \n",
            " [[ 0.          0.          0.01101238 ...  0.          0.00879162\n",
            "   0.00940172]\n",
            " [ 0.          0.          0.01908619 ... -0.02019649 -0.06922209\n",
            "   0.01919678]\n",
            " [ 0.          0.         -0.0249663  ... -0.0670498  -0.35492126\n",
            "  -0.03250464]\n",
            " ...\n",
            " [ 0.          0.          0.01285711 ...  0.01519828  0.01810379\n",
            "   0.01686959]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]]\n",
            "db2 is \n",
            " [[ 0.00476748]\n",
            " [-0.01424512]\n",
            " [-0.06038403]\n",
            " [-0.0173476 ]\n",
            " [ 0.        ]\n",
            " [ 0.02204353]\n",
            " [ 0.00348903]\n",
            " [-0.0394189 ]\n",
            " [-0.01463849]\n",
            " [ 0.        ]\n",
            " [ 0.        ]\n",
            " [ 0.        ]\n",
            " [-0.01512019]\n",
            " [-0.00198069]\n",
            " [ 0.        ]\n",
            " [-0.00804843]\n",
            " [-0.01537062]\n",
            " [ 0.        ]\n",
            " [ 0.01157471]\n",
            " [-0.02626636]\n",
            " [ 0.        ]\n",
            " [-0.00091999]\n",
            " [ 0.        ]\n",
            " [ 0.        ]\n",
            " [-0.00083161]\n",
            " [-0.02026755]\n",
            " [ 0.00778529]\n",
            " [ 0.00094976]\n",
            " [ 0.        ]\n",
            " [ 0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Update Parameters**"
      ],
      "metadata": {
        "id": "d-H57NsYeeIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_parameters(parameters, gradients, learning_rate):\n",
        "  '''\n",
        "  Input: Takes in all the parameters, gradients and learning rate\n",
        "  Output: Returns the updated parameters.\n",
        "  '''\n",
        "  L = len(parameters) // 2 # number of layers in the neural network\n",
        "  for l in range(L):\n",
        "      parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * gradients[\"dW\" + str(l+1)]\n",
        "      parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * gradients[\"db\" + str(l+1)]\n",
        "  \n",
        "  return parameters"
      ],
      "metadata": {
        "id": "2GgMc5edeWLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dimensions = [3072, 50, 30, 10] #  three-layer model"
      ],
      "metadata": {
        "id": "utACZW0vfFUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model**"
      ],
      "metadata": {
        "id": "QyhWycqXfHbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def L_layer_model(X, Y, dimensions, learning_rate = 0.0075, num_iterations = 3000, print_loss=False):\n",
        "  '''\n",
        "  Input: X and Y are the input training datasets, learning_rate, num_iterations are for gradient descent optimization.\n",
        "  Output: Returns the optimized parameters.\n",
        "  '''\n",
        "  np.random.seed(2)\n",
        "  losses = []# keep track of loss\n",
        "  \n",
        "  # Parameters initialization\n",
        "  parameters = initialize_parameters(dimensions)\n",
        "\n",
        "  for i in range(0, num_iterations):\n",
        "\n",
        "      # Forward propagation\n",
        "      HL, memories = L_layer_forward(X, parameters)\n",
        "      \n",
        "      # Compute loss\n",
        "      loss = compute_loss(HL, Y)\n",
        "  \n",
        "      # Backward propagation\n",
        "      gradients = L_layer_backward(HL, Y, memories)\n",
        "\n",
        "      # Update parameters.\n",
        "      parameters = update_parameters(parameters, gradients, learning_rate)\n",
        "      \n",
        "      # Printing the loss every 100 training example\n",
        "      if print_loss and i % 100 == 0:\n",
        "          print (\"Loss after iteration %i: %f\" %(i, loss))\n",
        "          losses.append(loss)\n",
        "          \n",
        "  # plotting the loss\n",
        "  plt.plot(np.squeeze(losses))\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('iterations (per tens)')\n",
        "  plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "  plt.show()\n",
        "  \n",
        "  return parameters"
      ],
      "metadata": {
        "id": "3tJNXskjfL3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set_x_new = train_set_x[:,0:5000]\n",
        "train_set_y_new = train_set_y[:,0:5000]\n",
        "train_set_x_new.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XF8nHnfTfMEH",
        "outputId": "8c3200b3-1f3f-4180-d87a-ed69d32939bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3072, 5000)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = L_layer_model(train_set_x_new, train_set_y_new, dimensions, num_iterations = 2000, print_loss = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "vBH1GTPzgtq6",
        "outputId": "572e7268-079b-4531-9935-9a6c3d8183a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss after iteration 0: 2.398166\n",
            "Loss after iteration 100: 2.255503\n",
            "Loss after iteration 200: 2.196709\n",
            "Loss after iteration 300: 2.136084\n",
            "Loss after iteration 400: 2.083826\n",
            "Loss after iteration 500: 2.042615\n",
            "Loss after iteration 600: 2.007436\n",
            "Loss after iteration 700: 1.976141\n",
            "Loss after iteration 800: 1.948974\n",
            "Loss after iteration 900: 1.925935\n",
            "Loss after iteration 1000: 1.905996\n",
            "Loss after iteration 1100: 1.888565\n",
            "Loss after iteration 1200: 1.873121\n",
            "Loss after iteration 1300: 1.859117\n",
            "Loss after iteration 1400: 1.846437\n",
            "Loss after iteration 1500: 1.834590\n",
            "Loss after iteration 1600: 1.823553\n",
            "Loss after iteration 1700: 1.813219\n",
            "Loss after iteration 1800: 1.803532\n",
            "Loss after iteration 1900: 1.794188\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def L_layer_model_L2_regularization(X, Y, dimensions, learning_rate = 0.0075, num_iterations = 3000, print_loss=False, lambdax = 0):\n",
        "  '''\n",
        "  Input: X and Y are the input training datasets, learning_rate, num_iterations are for gradient descent optimization.\n",
        "  Output: Returns the optimized parameters.\n",
        "  '''\n",
        "  np.random.seed(2)\n",
        "  losses = []# keep track of loss\n",
        "  \n",
        "  # Parameters initialization\n",
        "  parameters = initialize_parameters(dimensions)\n",
        "\n",
        "  for i in range(0, num_iterations):\n",
        "\n",
        "      # Forward propagation\n",
        "      HL, memories = L_layer_forward(X, parameters)\n",
        "      \n",
        "      # Compute loss\n",
        "      loss = compute_loss_with_L2(HL, Y, parameters, lambdax)\n",
        "  \n",
        "      # Backward propagation\n",
        "      gradients = L_layer_backward_with_L2(HL, Y, memories, lambdax)\n",
        "\n",
        "      # Update parameters.\n",
        "      parameters = update_parameters(parameters, gradients, learning_rate)\n",
        "      \n",
        "      # Printing the loss every 100 training example\n",
        "      if print_loss and i % 100 == 0:\n",
        "          print (\"Loss after iteration %i: %f\" %(i, loss))\n",
        "          losses.append(loss)\n",
        "          \n",
        "  # plotting the loss\n",
        "  plt.plot(np.squeeze(losses))\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('iterations (per tens)')\n",
        "  plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "  plt.show()\n",
        "  \n",
        "  return parameters"
      ],
      "metadata": {
        "id": "D4Z6HKnrS2de"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L2_parameters = L_layer_model_L2_regularization(train_set_x_new, train_set_y_new, dimensions, num_iterations = 2000, print_loss = True, lambdax = 0.7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "OZSVKbwWSsvj",
        "outputId": "e55a5f4f-e18b-4f14-9773-d2986077794d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss after iteration 0: 2.506516\n",
            "Loss after iteration 100: 2.363841\n",
            "Loss after iteration 200: 2.305048\n",
            "Loss after iteration 300: 2.244432\n",
            "Loss after iteration 400: 2.192190\n",
            "Loss after iteration 500: 2.150999\n",
            "Loss after iteration 600: 2.115837\n",
            "Loss after iteration 700: 2.084560\n",
            "Loss after iteration 800: 2.057414\n",
            "Loss after iteration 900: 2.034397\n",
            "Loss after iteration 1000: 2.014478\n",
            "Loss after iteration 1100: 1.997070\n",
            "Loss after iteration 1200: 1.981641\n",
            "Loss after iteration 1300: 1.967642\n",
            "Loss after iteration 1400: 1.954983\n",
            "Loss after iteration 1500: 1.943142\n",
            "Loss after iteration 1600: 1.932125\n",
            "Loss after iteration 1700: 1.921804\n",
            "Loss after iteration 1800: 1.912131\n",
            "Loss after iteration 1900: 1.902799\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, y, parameters):\n",
        "  '''\n",
        "  Input: Input data X, y, optimized parameters\n",
        "  Output: returns the predicitons\n",
        "  '''\n",
        "  m = X.shape[1]\n",
        "  n = len(parameters) // 2 # number of layers in the neural network\n",
        "  \n",
        "  # Forward propagation\n",
        "  probas, caches = L_layer_forward(X, parameters)\n",
        "  \n",
        "  p = np.argmax(probas, axis = 0)\n",
        "  act = np.argmax(y, axis = 0)\n",
        "\n",
        "  print(\"Accuracy: \"  + str(np.sum((p == act)/m)))\n",
        "      \n",
        "  return p"
      ],
      "metadata": {
        "id": "jJ2y-zG3gtul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train set predictions\n",
        "pred_train = predict(train_set_x_new, train_set_y_new, parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ji4eRknQgtws",
        "outputId": "9005cc34-10ba-446c-a068-fd6d5b7c2d5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8774000000000002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test set predicitons\n",
        "pred_test = predict(test_set_x, test_set_y, parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41IkJb-1iTtA",
        "outputId": "3323874c-2fd4-4e9c-97d8-bb99122368aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8674000000000002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iBhmpbfmkTA9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}