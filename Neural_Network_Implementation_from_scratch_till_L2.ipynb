{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Network Implementation from scratch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Data** **Preparation**"
      ],
      "metadata": {
        "id": "cF5zCrVl4LuY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DcyoXPch4KlY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import gzip\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "import sklearn\n",
        "import sklearn.datasets\n",
        "import scipy\n",
        "from PIL import Image\n",
        "from scipy import ndimage\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "  '''\n",
        "  Reads the .pkl file and loads data into variables\n",
        "  '''\n",
        "  f = gzip.open('mnist.pkl.gz', 'rb')\n",
        "  f.seek(0)\n",
        "  training_data, validation_data, test_data = pickle.load(f, encoding='latin1')\n",
        "  f.close()\n",
        "  return (training_data, validation_data, test_data)"
      ],
      "metadata": {
        "id": "YVi1OffT4RzT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data, validation_data, test_data = load_data()"
      ],
      "metadata": {
        "id": "mI0nlA2P4WEU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpAFriOX4WHD",
        "outputId": "3b8dfecf-7712-4bdc-eebe-ac9279c88d08"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
              " array([5, 0, 4, ..., 8, 4, 8]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input and target label shapes\n",
        "print(training_data[0].shape)\n",
        "print(training_data[1].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWwaNshU4WJ8",
        "outputId": "56e29679-faa1-4347-f0eb-33d44df6d10c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 784)\n",
            "(50000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The feature dataset is:\" + str(training_data[0]))\n",
        "print(\"The target dataset is:\" + str(training_data[1]))\n",
        "print(\"The number of examples in the training dataset is:\" + str(len(training_data[0])))\n",
        "print(\"The number of points in a single input is:\" + str(len(training_data[0][1])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmAaAclG4WM4",
        "outputId": "b71435b1-80d6-47ee-e610-0c9143c5a552"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The feature dataset is:[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "The target dataset is:[5 0 4 ... 8 4 8]\n",
            "The number of examples in the training dataset is:50000\n",
            "The number of points in a single input is:784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **One-Hot Representation**"
      ],
      "metadata": {
        "id": "C12PJ8Td4leN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot(j):\n",
        "  '''\n",
        "  Input: List of m labels\n",
        "  Output: Returns (10, m) matrix with one-hot representation\n",
        "  '''\n",
        "  n = j.shape[0]\n",
        "  new_array = np.zeros((10, n))\n",
        "  index = 0\n",
        "  for res in j:\n",
        "      new_array[res][index] = 1.0\n",
        "      index = index + 1\n",
        "  return new_array"
      ],
      "metadata": {
        "id": "zyGOvvye4WPy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_wrapper():\n",
        "  '''\n",
        "  Converts the dataset into desired shape and also converts the ground truth to one-hot representation\n",
        "  '''\n",
        "  tr_d, va_d, te_d = load_data()\n",
        "  training_inputs = np.array(tr_d[0][:]).T\n",
        "  training_results = np.array(tr_d[1][:])\n",
        "  train_set_y = one_hot(training_results)\n",
        "  \n",
        "  validation_inputs = np.array(va_d[0][:]).T\n",
        "  validation_results = np.array(va_d[1][:])\n",
        "  validation_set_y = one_hot(validation_results)\n",
        "  \n",
        "  test_inputs = np.array(te_d[0][:]).T\n",
        "  test_results = np.array(te_d[1][:])\n",
        "  test_set_y = one_hot(test_results)\n",
        "  \n",
        "  return (training_inputs, train_set_y, test_inputs, test_set_y)"
      ],
      "metadata": {
        "id": "XSMmVG0T4WSn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set_x, train_set_y, test_set_x, test_set_y = data_wrapper()"
      ],
      "metadata": {
        "id": "37OOVcGVBpcA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"train_set_x shape: \" + str(train_set_x.shape))\n",
        "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
        "print (\"test_set_x shape: \" + str(test_set_x.shape))\n",
        "print (\"test_set_y shape: \" + str(test_set_y.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iS8fJv8PBpfA",
        "outputId": "2f7a91b9-608d-420d-b807-9b1cab73f366"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_set_x shape: (784, 50000)\n",
            "train_set_y shape: (10, 50000)\n",
            "test_set_x shape: (784, 10000)\n",
            "test_set_y shape: (10, 10000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting labels into dataframe.\n",
        "y = pd.DataFrame(train_set_y)"
      ],
      "metadata": {
        "id": "jMaI0zzFBph7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The target dataset is:\" + str(training_data[1]))\n",
        "print(\"The one hot encoding dataset is:\")\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "id": "3G_Ye_70BzGR",
        "outputId": "d83059e7-7bf9-427b-e93e-a438c1e951c0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The target dataset is:[5 0 4 ... 8 4 8]\n",
            "The one hot encoding dataset is:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0      1      2      3      4      5      6      7      8      9      ...  \\\n",
              "0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
              "1    0.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    1.0    0.0  ...   \n",
              "2    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0  ...   \n",
              "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0  ...   \n",
              "4    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0  ...   \n",
              "5    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
              "6    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
              "7    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
              "8    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
              "9    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
              "\n",
              "   49990  49991  49992  49993  49994  49995  49996  49997  49998  49999  \n",
              "0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0  \n",
              "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
              "2    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
              "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
              "4    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0  \n",
              "5    0.0    1.0    1.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0  \n",
              "6    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
              "7    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
              "8    1.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0  \n",
              "9    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
              "\n",
              "[10 rows x 50000 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ae137152-836f-4b8e-8352-4070170f2a21\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>49990</th>\n",
              "      <th>49991</th>\n",
              "      <th>49992</th>\n",
              "      <th>49993</th>\n",
              "      <th>49994</th>\n",
              "      <th>49995</th>\n",
              "      <th>49996</th>\n",
              "      <th>49997</th>\n",
              "      <th>49998</th>\n",
              "      <th>49999</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 50000 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae137152-836f-4b8e-8352-4070170f2a21')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ae137152-836f-4b8e-8352-4070170f2a21 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ae137152-836f-4b8e-8352-4070170f2a21');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing a random training sample.\n",
        "index  = 1000\n",
        "k = train_set_x[:,index]\n",
        "k = k.reshape((28, 28))\n",
        "plt.title('Label is {label}'.format(label= training_data[1][index]))\n",
        "plt.imshow(k, cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "zyIQv47VBzI0",
        "outputId": "a2ab6144-ecf2-40fd-9bc9-9813db57fd17"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fda26285cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Feedforward**"
      ],
      "metadata": {
        "id": "nwhc0NPuCNDc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Activation Functions"
      ],
      "metadata": {
        "id": "66JFBL4NCbFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(Z):\n",
        "  '''\n",
        "  Input: Z is the cummulation input to the layer\n",
        "  Output: Returns  sigmoid activation H matrix, sigmoid_memory later used in the backpropogation.\n",
        "  '''\n",
        "   \n",
        "  H = 1/(1+np.exp(-Z))\n",
        "  sigmoid_memory = Z\n",
        "  \n",
        "  return H, sigmoid_memory"
      ],
      "metadata": {
        "id": "rNopgScSCMUx"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Z = np.arange(8).reshape(4,2)\n",
        "print (\"sigmoid(Z) = \" + str(sigmoid(Z)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14t4kydxHkF2",
        "outputId": "593951f2-a97e-4a5b-febe-db46fcaf073b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sigmoid(Z) = (array([[0.5       , 0.73105858],\n",
            "       [0.88079708, 0.95257413],\n",
            "       [0.98201379, 0.99330715],\n",
            "       [0.99752738, 0.99908895]]), array([[0, 1],\n",
            "       [2, 3],\n",
            "       [4, 5],\n",
            "       [6, 7]]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(Z):\n",
        "  '''\n",
        "  Input: Z is the cummulation input to the layer\n",
        "  Output: Returns relu activation H matrix, relu_memory later used in the backpropogation.\n",
        "  '''\n",
        "\n",
        "  H = np.maximum(0,Z)\n",
        "  assert(H.shape == Z.shape)\n",
        "  \n",
        "  relu_memory = Z \n",
        "  return H, relu_memory"
      ],
      "metadata": {
        "id": "JxxEpArPBzMD"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Z = np.array([1, 3, -1, -4, -5, 7, 9, 18]).reshape(4,2)\n",
        "print (\"relu(Z) = \" + str(relu(Z)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3Rzx8XSHkfj",
        "outputId": "bee89158-5344-482c-d0f4-f2ae7541e13e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "relu(Z) = (array([[ 1,  3],\n",
            "       [ 0,  0],\n",
            "       [ 0,  7],\n",
            "       [ 9, 18]]), array([[ 1,  3],\n",
            "       [-1, -4],\n",
            "       [-5,  7],\n",
            "       [ 9, 18]]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(Z):\n",
        "  '''\n",
        "  Input: Z is the cummulation input to the layer\n",
        "  Output: Returns softmax activation H matrix, softmax_memory later used in the backpropogation.\n",
        "  '''\n",
        "  Z_exp = np.exp(Z)\n",
        "\n",
        "  Z_sum = np.sum(Z_exp,axis = 0, keepdims = True)\n",
        "  \n",
        "  H = Z_exp/Z_sum  #normalising step\n",
        "  softmax_memory = Z\n",
        "  \n",
        "  return H, softmax_memory"
      ],
      "metadata": {
        "id": "DFb31iYPBzQB"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Z = np.array([[11,19,10], [12, 21, 23]])\n",
        "H, softmax_memory = softmax(Z)\n",
        "print(H)\n",
        "print(softmax_memory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrnzMOlZHlBu",
        "outputId": "ac0740f6-2f79-441d-9950-0aa1e60f439d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.68941421e-01 1.19202922e-01 2.26032430e-06]\n",
            " [7.31058579e-01 8.80797078e-01 9.99997740e-01]]\n",
            "[[11 19 10]\n",
            " [12 21 23]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Initializing Parameters**"
      ],
      "metadata": {
        "id": "WfHRa_0XG1TP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_parameters(dimensions):\n",
        "  '''\n",
        "  Input: dimensions is a list containing the number of neuron in each layer in the network\n",
        "  Output: Returns parameters which is a python dictionary containing the parameters \"W1\", \"b1\", ..., \"WL\", \"bL\"\n",
        "  '''\n",
        "  np.random.seed(2)\n",
        "  parameters = {}\n",
        "  L = len(dimensions)            # number of layers in the network + 1\n",
        "\n",
        "  for l in range(1, L): \n",
        "      parameters['W' + str(l)] = np.random.randn(dimensions[l], dimensions[l-1]) * 0.1\n",
        "      parameters['b' + str(l)] = np.zeros((dimensions[l], 1)) \n",
        "      \n",
        "      assert(parameters['W' + str(l)].shape == (dimensions[l], dimensions[l-1]))\n",
        "      assert(parameters['b' + str(l)].shape == (dimensions[l], 1))\n",
        "\n",
        "  return parameters"
      ],
      "metadata": {
        "id": "8ZtECxcVBzUN"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dimensions  = [784, 3,7,10]\n",
        "parameters = initialize_parameters(dimensions)\n",
        "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
        "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
        "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
        "print(\"b2 = \" + str(parameters[\"b2\"]))\n",
        "# print(\"W3 = \" + str(parameters[\"W3\"]))\n",
        "# print(\"b3 = \" + str(parameters[\"b3\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWeJPMJELPaF",
        "outputId": "0e1e4167-a21d-4437-fe95-721d6e65d793"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W1 = [[-0.04167578 -0.00562668 -0.21361961 ... -0.06168445  0.03213358\n",
            "  -0.09464469]\n",
            " [-0.05301394 -0.1259207   0.16775441 ... -0.03284246 -0.05623108\n",
            "   0.01179136]\n",
            " [ 0.07386378 -0.15872956  0.01532001 ... -0.08428557  0.10040469\n",
            "   0.00545832]]\n",
            "b1 = [[0.]\n",
            " [0.]\n",
            " [0.]]\n",
            "W2 = [[ 0.06650944 -0.19626047  0.2112715 ]\n",
            " [-0.28074571 -0.13967752  0.02641189]\n",
            " [ 0.10925169  0.06646016  0.08565535]\n",
            " [-0.11058228  0.03715795  0.13440124]\n",
            " [-0.16421272 -0.1153127   0.02013163]\n",
            " [ 0.13985659  0.07228733 -0.10717236]\n",
            " [-0.05673344 -0.03663499 -0.15460347]]\n",
            "b2 = [[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Forward Pass**"
      ],
      "metadata": {
        "id": "bhb-imHOHYKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This performs one forward propogation for a certain layer 'l'\n",
        "def layer_forward(H_prev, W, b, activation = 'relu'): \n",
        "  '''\n",
        "  Input: H_prev this is the input cummulative to the current layer, W is weights matrix of shape\n",
        "  b is bias vector of shape, activation to be used for forward propagation : \"softmax\", \"relu\", \"sigmoid\"\n",
        "  Output: Returns H is the output of the activation function, memory is a python dictionary containing linear or activation memory.\n",
        "  '''\n",
        "  \n",
        "  Z = np.dot(W, H_prev) + b\n",
        "  if activation == \"sigmoid\":\n",
        "      linear_memory = (H_prev, W, b)\n",
        "      H, activation_memory = sigmoid(Z)\n",
        "\n",
        "  elif activation == \"softmax\":\n",
        "      linear_memory = (H_prev, W, b)\n",
        "      H, activation_memory = softmax(Z)\n",
        "  \n",
        "  elif activation == \"relu\":\n",
        "      linear_memory = (H_prev, W, b)\n",
        "      H, activation_memory = relu(Z)\n",
        "      \n",
        "  assert (H.shape == (W.shape[0], H_prev.shape[1]))\n",
        "  memory = (linear_memory, activation_memory)\n",
        "\n",
        "  return H, memory"
      ],
      "metadata": {
        "id": "BbSs_goKBzXQ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "H_prev = np.array([[1,0, 5, 10, 2], [2, 5, 3, 10, 2]])\n",
        "W_sample = np.array([[10, 5], [2, 0], [1, 0]])\n",
        "b_sample = np.array([10, 5, 0]).reshape((3, 1))\n",
        "\n",
        "H = layer_forward(H_prev, W_sample, b_sample, activation=\"sigmoid\")[0]\n",
        "H"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1x68q1AoBzaW",
        "outputId": "54e95561-734c-4207-adf4-2990191d2211"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 1.        , 1.        , 1.        , 1.        ],\n",
              "       [0.99908895, 0.99330715, 0.99999969, 1.        , 0.99987661],\n",
              "       [0.73105858, 0.5       , 0.99330715, 0.9999546 , 0.88079708]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This performs one forward pass through the whole network for all training samples.\n",
        "\n",
        "def L_layer_forward(X, parameters):\n",
        "  '''\n",
        "  Input: X is input data, parameters is output of initialize_parameters()\n",
        "  Output: HL is the last layer's post-activation value, memories is the list of memory containing \n",
        "  -every memory of relu forward (there are L-1 of them, indexed from 1 to L-1), \n",
        "  - the memory of softmax forward (there is one, indexed L)\n",
        "  '''\n",
        "\n",
        "  memories = []\n",
        "  H = X\n",
        "  L = len(parameters) // 2   # number of layers in the neural network\n",
        "  \n",
        "  for l in range(1, L):\n",
        "      H_prev = H\n",
        "      W=parameters[\"W\"+str(l)]\n",
        "      b=parameters[\"b\"+str(l)]\n",
        "      H, memory = layer_forward(H_prev, W, b, activation = 'relu')\n",
        "      \n",
        "      memories.append(memory)\n",
        "  # HL here is the final prediction in the final layer.\n",
        "  W=parameters[\"W\"+str(L)]\n",
        "  b=parameters[\"b\"+str(L)]\n",
        "  HL, memory = layer_forward(H, W, b, activation = 'softmax')\n",
        "  \n",
        "  memories.append(memory)\n",
        "\n",
        "  assert(HL.shape == (10, X.shape[1]))\n",
        "          \n",
        "  return HL, memories"
      ],
      "metadata": {
        "id": "_SNkOeisHjOo"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# verify\n",
        "# X is (784, 10)\n",
        "# HL should be (10, 10)\n",
        "x_sample = train_set_x[:, 10:20]\n",
        "print(x_sample.shape)\n",
        "HL = L_layer_forward(x_sample, parameters=parameters)[0]\n",
        "print(HL[:, :5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9Vo4uRhYfNz",
        "outputId": "9a276949-a392-4965-ae8f-66ccd5b96a09"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(784, 10)\n",
            "[[0.10106734 0.10045152 0.09927757 0.10216656 0.1       ]\n",
            " [0.10567625 0.10230873 0.10170271 0.11250099 0.1       ]\n",
            " [0.09824287 0.0992886  0.09967128 0.09609693 0.1       ]\n",
            " [0.10028288 0.10013048 0.09998149 0.10046076 0.1       ]\n",
            " [0.09883601 0.09953443 0.09931419 0.097355   0.1       ]\n",
            " [0.10668575 0.10270912 0.10180736 0.11483609 0.1       ]\n",
            " [0.09832513 0.09932275 0.09954792 0.09627089 0.1       ]\n",
            " [0.09747092 0.09896735 0.0995387  0.09447277 0.1       ]\n",
            " [0.09489069 0.09788255 0.09929998 0.08915178 0.1       ]\n",
            " [0.09852217 0.09940447 0.09985881 0.09668824 0.1       ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Loss**"
      ],
      "metadata": {
        "id": "0eWUZjRLYj0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross entropy loss\n",
        "def compute_loss(HL, Y):\n",
        "  '''\n",
        "  Input: HL is the output probability from the network, Y is the true labels\n",
        "  Output: Cross-entropy loss\n",
        "  '''\n",
        "  m = Y.shape[1]\n",
        "  loss = -(1./m)*np.sum(np.multiply(Y,np.log(HL)))\n",
        "  \n",
        "  loss = np.squeeze(loss) # To make sure that the loss's shape is what we expect (e.g. this turns [[17]] into 17).\n",
        "  assert(loss.shape == ())\n",
        "  \n",
        "  return loss"
      ],
      "metadata": {
        "id": "zmphsLWiYfQ5"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample\n",
        "\n",
        "np.random.seed(2)\n",
        "HL_sample = np.random.rand(10,5)\n",
        "Y_sample = train_set_y[:, 10:15]\n",
        "print(HL_sample)\n",
        "print(Y_sample)\n",
        "\n",
        "print(compute_loss(HL_sample, Y_sample))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1Z-mE6nYfU3",
        "outputId": "4add9f0d-ad4f-4bf5-bad2-1dd21afb9372"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.4359949  0.02592623 0.54966248 0.43532239 0.4203678 ]\n",
            " [0.33033482 0.20464863 0.61927097 0.29965467 0.26682728]\n",
            " [0.62113383 0.52914209 0.13457995 0.51357812 0.18443987]\n",
            " [0.78533515 0.85397529 0.49423684 0.84656149 0.07964548]\n",
            " [0.50524609 0.0652865  0.42812233 0.09653092 0.12715997]\n",
            " [0.59674531 0.226012   0.10694568 0.22030621 0.34982629]\n",
            " [0.46778748 0.20174323 0.64040673 0.48306984 0.50523672]\n",
            " [0.38689265 0.79363745 0.58000418 0.1622986  0.70075235]\n",
            " [0.96455108 0.50000836 0.88952006 0.34161365 0.56714413]\n",
            " [0.42754596 0.43674726 0.77655918 0.53560417 0.95374223]]\n",
            "[[0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [1. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n",
            "0.8964600261334037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross entropy loss with L2 regularization\n",
        "def compute_loss_with_L2(HL, Y, parameters, lambdax):\n",
        "  '''\n",
        "  Input: HL is the output probability from the network, Y is the true labels\n",
        "  Output: Cross-entropy loss\n",
        "  '''\n",
        "\n",
        "  L = len(parameters) // 2   # Number of layers\n",
        "\n",
        "  m = Y.shape[1]\n",
        "  loss = -(1./m)*np.sum(np.multiply(Y,np.log(HL)))\n",
        "  total_sum  =0\n",
        "  for l in range(1, L):\n",
        "    total_sum += np.sum(np.square(parameters[\"W\"+str(l)]))\n",
        "  L2_regularization_cost = (lambdax/(2*m))*total_sum\n",
        "  # L2_regularization_cost = (lambdax/(2*m))*(np.sum(np.square(W1) + np.sum(np.square(W2) + np.sum(np.square(W2)))\n",
        "  # print(\"L2 loss before \", L2_regularization_cost)\n",
        "  loss = loss + L2_regularization_cost\n",
        "  loss = np.squeeze(loss) # To make sure that the loss's shape is what we expect (e.g. this turns [[17]] into 17).\n",
        "  assert(loss.shape == ())\n",
        "  \n",
        "  return loss"
      ],
      "metadata": {
        "id": "XQCXS59cT5Dn"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample\n",
        "\n",
        "np.random.seed(2)\n",
        "HL_sample = np.random.rand(10,5)\n",
        "Y_sample = train_set_y[:, 10:15]\n",
        "print(HL_sample)\n",
        "print(Y_sample)\n",
        "\n",
        "print(compute_loss_with_L2(HL_sample, Y_sample, parameters, 0.7))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9bf3B_wXRvt",
        "outputId": "1f7c871e-e49a-4c42-b59c-ec500b4d6cb3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.4359949  0.02592623 0.54966248 0.43532239 0.4203678 ]\n",
            " [0.33033482 0.20464863 0.61927097 0.29965467 0.26682728]\n",
            " [0.62113383 0.52914209 0.13457995 0.51357812 0.18443987]\n",
            " [0.78533515 0.85397529 0.49423684 0.84656149 0.07964548]\n",
            " [0.50524609 0.0652865  0.42812233 0.09653092 0.12715997]\n",
            " [0.59674531 0.226012   0.10694568 0.22030621 0.34982629]\n",
            " [0.46778748 0.20174323 0.64040673 0.48306984 0.50523672]\n",
            " [0.38689265 0.79363745 0.58000418 0.1622986  0.70075235]\n",
            " [0.96455108 0.50000836 0.88952006 0.34161365 0.56714413]\n",
            " [0.42754596 0.43674726 0.77655918 0.53560417 0.95374223]]\n",
            "[[0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [1. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n",
            "2.5432468864562114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **BackPropogation**"
      ],
      "metadata": {
        "id": "WTGEldWbZj-J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **sigmoid-backward & relu-backward**"
      ],
      "metadata": {
        "id": "IMV7ICtEaCeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Backpropogation fo the sigmoid function\n",
        "def sigmoid_backward(dH, sigmoid_memory):\n",
        "  '''\n",
        "  Input: dH is gradient of the sigmoid activated activation of shape same as H or Z in the same layer,\n",
        "  sigmoid_memory is the memory stored in the sigmoid(Z) calculation.\n",
        "  Output: Returns derivate of Loss w.r.t Z\n",
        "  '''\n",
        "  # sigmoid_memory is the memory stored in the sigmoid(Z) calculation\n",
        "  \n",
        "  Z = sigmoid_memory\n",
        "  \n",
        "  H = 1/(1+np.exp(-Z))\n",
        "  dZ = dH * H * (1-H)\n",
        "  \n",
        "  assert (dZ.shape == Z.shape)\n",
        "  \n",
        "  return dZ"
      ],
      "metadata": {
        "id": "adriZS-lZgq_"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Backpropogation fo the sigmoid function\n",
        "def relu_backward(dH, relu_memory):\n",
        "  '''\n",
        "  Input: dH is gradient of the relu activated activation of shape same as H or Z in the same layer,\n",
        "  relu_memory is the memory stored in the relu(Z) calculation.\n",
        "  Output: Returns derivate of Loss w.r.t Z\n",
        "  '''\n",
        "\n",
        "  Z = relu_memory\n",
        "  dZ = np.array(dH, copy=True) # dZ will be the same as dA wherever the elements of A weren't 0\n",
        "  \n",
        "  dZ[Z <= 0] = 0\n",
        "  \n",
        "  assert (dZ.shape == Z.shape)\n",
        "  \n",
        "  return dZ"
      ],
      "metadata": {
        "id": "iYrECScpZgvY"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Graded\n",
        "\n",
        "def layer_backward(dH, memory, activation = 'relu'):\n",
        "  '''\n",
        "  Input: takes dH and the memory calculated in layer_forward and activation\n",
        "  Output: Returns to calculate the dH_prev, dW, db\n",
        "  '''\n",
        "\n",
        "\n",
        "  linear_memory, activation_memory = memory\n",
        "  \n",
        "  if activation == \"relu\":\n",
        "      dZ = relu_backward(dH,activation_memory)\n",
        "      H_prev, W, b = linear_memory\n",
        "      m = H_prev.shape[1]\n",
        "      dW = (1./m) * np.dot(dZ,H_prev.transpose())\n",
        "      db = (1./m) * np.sum(dZ,axis=1)\n",
        "      db = np.reshape(db,(-1, 1))\n",
        "      dH_prev = np.dot(W.transpose(),dZ)\n",
        "      \n",
        "  elif activation == \"sigmoid\":\n",
        "      dZ = sigmoid_backward(dH, activation_memory)\n",
        "      H_prev, W, b = linear_memory\n",
        "      m = H_prev.shape[1]\n",
        "      dW = (1./m) * np.dot(dZ,H_prev.transpose())\n",
        "      db = (1./m) * np.sum(dZ,axis=1)\n",
        "      db = np.reshape(db,(-1, 1))\n",
        "      dH_prev = np.dot(W.transpose(),dZ)\n",
        "  \n",
        "  return dH_prev, dW, db"
      ],
      "metadata": {
        "id": "n5_7-1sFZgx_"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "H_prev = np.array([[1,0, 5, 10, 2], [2, 5, 3, 10, 2]])\n",
        "W_sample = np.array([[10, 5], [2, 0], [1, 0]])\n",
        "b_sample = np.array([10, 5, 0]).reshape((3, 1))\n",
        "\n",
        "H, memory = layer_forward(H_prev, W_sample, b_sample, activation=\"relu\")\n",
        "np.random.seed(2)\n",
        "dH = np.random.rand(3,5)\n",
        "dH_prev, dW, db = layer_backward(dH, memory, activation = 'relu')\n",
        "print('dH_prev is \\n' , dH_prev)\n",
        "print('dW is \\n' ,dW)\n",
        "print('db is \\n', db)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19uUnRgReOz3",
        "outputId": "0a617492-f17c-43f1-9e16-9956b9b790b2"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dH_prev is \n",
            " [[5.6417525  0.66855959 6.86974666 5.46611139 4.92177244]\n",
            " [2.17997451 0.12963116 2.74831239 2.17661196 2.10183901]]\n",
            "dW is \n",
            " [[1.67565336 1.56891359]\n",
            " [1.39137819 1.4143854 ]\n",
            " [1.3597389  1.43013369]]\n",
            "db is \n",
            " [[0.37345476]\n",
            " [0.34414727]\n",
            " [0.29074635]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def L_layer_backward(HL, Y, memories):\n",
        "  '''\n",
        "  Input: predicted value HL and the true target value Y and memories calculated by L_layer_forward\n",
        "  Output: Returns gradient.\n",
        "  '''\n",
        "\n",
        "  gradients = {}\n",
        "  L = len(memories) # the number of layers\n",
        "  m = HL.shape[1]\n",
        "  Y = Y.reshape(HL.shape) # after this line, Y is the same shape as AL\n",
        "  \n",
        "  # Perform the backprop for the last layer that is the softmax layer\n",
        "  current_memory = memories[-1]\n",
        "  linear_memory, activation_memory = current_memory\n",
        "  dZ = HL - Y\n",
        "  H_prev, W, b = linear_memory\n",
        "  \n",
        "  gradients[\"dH\" + str(L-1)] = np.dot(W.transpose(),dZ)\n",
        "  gradients[\"dW\" + str(L)] = (1./m) * np.dot(dZ,H_prev.transpose())\n",
        "  db = (1./m) * np.sum(dZ,axis=1)\n",
        "  db = np.reshape(db,(-1, 1))\n",
        "  gradients[\"db\" + str(L)] = db\n",
        "  \n",
        "  # Perform the backpropagation l-1 times\n",
        "  for l in reversed(range(L-1)):\n",
        "      # Lth layer gradients: \"gradients[\"dH\" + str(l + 1)] \", gradients[\"dW\" + str(l + 2)] , gradients[\"db\" + str(l + 2)]\n",
        "      current_memory = memories[l]\n",
        "      \n",
        "      dH_prev_temp, dW_temp, db_temp = layer_backward(gradients[\"dH\" + str(l + 1)], current_memory, activation = 'relu')\n",
        "      gradients[\"dH\" + str(l)] = dH_prev_temp\n",
        "      gradients[\"dW\" + str(l + 1)] = dW_temp\n",
        "      gradients[\"db\" + str(l + 1)] = db_temp\n",
        "\n",
        "\n",
        "  return gradients"
      ],
      "metadata": {
        "id": "OR5gNsOnYfWd"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def L_layer_backward_with_L2(HL, Y, memories, lambdax):\n",
        "  '''\n",
        "  Input: predicted value HL and the true target value Y and memories calculated by L_layer_forward\n",
        "  Output: Returns gradient.\n",
        "  '''\n",
        "\n",
        "  gradients = {}\n",
        "  L = len(memories) # the number of layers\n",
        "  m = HL.shape[1]\n",
        "  Y = Y.reshape(HL.shape) # after this line, Y is the same shape as AL\n",
        "  \n",
        "  # Perform the backprop for the last layer that is the softmax layer\n",
        "  current_memory = memories[-1]\n",
        "  linear_memory, activation_memory = current_memory\n",
        "  dZ = HL - Y\n",
        "  H_prev, W, b = linear_memory\n",
        "  \n",
        "  gradients[\"dH\" + str(L-1)] = np.dot(W.transpose(),dZ)\n",
        "  gradients[\"dW\" + str(L)] = (1./m) * np.dot(dZ,H_prev.transpose())\n",
        "  gradients[\"dW\" + str(L)] += (lambdax * gradients[\"dW\" + str(L)])/m\n",
        "  db = (1./m) * np.sum(dZ,axis=1)\n",
        "  db = np.reshape(db,(-1, 1))\n",
        "  gradients[\"db\" + str(L)] = db\n",
        "  \n",
        "  # Perform the backpropagation l-1 times\n",
        "  for l in reversed(range(L-1)):\n",
        "      # Lth layer gradients: \"gradients[\"dH\" + str(l + 1)] \", gradients[\"dW\" + str(l + 2)] , gradients[\"db\" + str(l + 2)]\n",
        "      current_memory = memories[l]\n",
        "      \n",
        "      dH_prev_temp, dW_temp, db_temp = layer_backward(gradients[\"dH\" + str(l + 1)], current_memory, activation = 'relu')\n",
        "      gradients[\"dH\" + str(l)] = dH_prev_temp\n",
        "      gradients[\"dW\" + str(l + 1)] = dW_temp\n",
        "      # print(\"checking shape:\",(lambdax * gradients[\"dW\" + str(l+1)])/m)\n",
        "      gradients[\"dW\" + str(l + 1)] += (lambdax * gradients[\"dW\" + str(l+1)])/m\n",
        "      gradients[\"db\" + str(l + 1)] = db_temp\n",
        "\n",
        "\n",
        "  return gradients"
      ],
      "metadata": {
        "id": "hhtMhDSzZrWy"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_sample = train_set_x[:, 10:20]\n",
        "y_sample = train_set_y[:, 10:20]\n",
        "\n",
        "HL, memories = L_layer_forward(x_sample, parameters=parameters)\n",
        "gradients  = L_layer_backward_with_L2(HL, y_sample, memories, 0.7)\n",
        "print('dW3 is \\n', gradients['dW3'])\n",
        "print('db3 is \\n', gradients['db3'])\n",
        "print('dW2 is \\n', gradients['dW2'])\n",
        "print('db2 is \\n', gradients['db2'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5mVHSFreWEH",
        "outputId": "1d8634ee-11d2-4600-985e-da13f06a7337"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dW3 is \n",
            " [[ 0.0214396   0.00203761  0.0108255   0.015596    0.00156695  0.00064053\n",
            "   0.        ]\n",
            " [ 0.02305365  0.00217765  0.01161644  0.0167677   0.00167422  0.0006477\n",
            "   0.        ]\n",
            " [-0.01838696 -0.00292871 -0.00534038 -0.00975984 -0.00221881  0.00064196\n",
            "   0.        ]\n",
            " [-0.01221403 -0.00169725 -0.00649543 -0.00989439 -0.00127992  0.00064608\n",
            "   0.        ]\n",
            " [ 0.02079195  0.00197105  0.01053461  0.01515513  0.00151594  0.0006386\n",
            "   0.        ]\n",
            " [ 0.01118628  0.00068452  0.00682254  0.00923737  0.00053626  0.00064672\n",
            "   0.        ]\n",
            " [-0.06782635 -0.00799559 -0.02591208 -0.04104208 -0.0062181   0.00064564\n",
            "   0.        ]\n",
            " [ 0.02045169  0.00193135  0.00752318  0.01290805  0.00148554 -0.00150372\n",
            "   0.        ]\n",
            " [-0.01927716  0.0018572  -0.01593474 -0.02167901  0.00142875  0.00064482\n",
            "   0.        ]\n",
            " [ 0.02078132  0.00196217  0.00636036  0.01271105  0.00150916 -0.00364833\n",
            "   0.        ]]\n",
            "db3 is \n",
            " [[ 0.10031756]\n",
            " [ 0.00460183]\n",
            " [-0.00142942]\n",
            " [-0.0997827 ]\n",
            " [ 0.09872663]\n",
            " [ 0.00536378]\n",
            " [-0.10124784]\n",
            " [-0.00191121]\n",
            " [-0.00359044]\n",
            " [-0.00104818]]\n",
            "dW2 is \n",
            " [[ 5.29038983e-05  1.21140600e-02  5.82273006e-02]\n",
            " [-5.14955777e-05 -3.17789409e-05 -1.94632553e-02]\n",
            " [ 6.02864036e-05  5.10593378e-03  4.33146948e-02]\n",
            " [ 1.60251201e-04 -2.03065592e-03 -8.46617565e-03]\n",
            " [ 2.11716720e-04  1.30654581e-04  2.82630406e-02]\n",
            " [ 0.00000000e+00 -4.02112173e-04  1.75379529e-05]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "db2 is \n",
            " [[ 0.013979  ]\n",
            " [-0.01329383]\n",
            " [ 0.01275707]\n",
            " [-0.01052957]\n",
            " [ 0.03179224]\n",
            " [-0.00039877]\n",
            " [ 0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Update Parameters**"
      ],
      "metadata": {
        "id": "d-H57NsYeeIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_parameters(parameters, gradients, learning_rate):\n",
        "  '''\n",
        "  Input: Takes in all the parameters, gradients and learning rate\n",
        "  Output: Returns the updated parameters.\n",
        "  '''\n",
        "  L = len(parameters) // 2 # number of layers in the neural network\n",
        "  for l in range(L):\n",
        "      parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * gradients[\"dW\" + str(l+1)]\n",
        "      parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * gradients[\"db\" + str(l+1)]\n",
        "  \n",
        "  return parameters"
      ],
      "metadata": {
        "id": "2GgMc5edeWLV"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dimensions = [784, 45, 10] #  three-layer model"
      ],
      "metadata": {
        "id": "utACZW0vfFUG"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model**"
      ],
      "metadata": {
        "id": "QyhWycqXfHbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def L_layer_model(X, Y, dimensions, learning_rate = 0.0075, num_iterations = 3000, print_loss=False):\n",
        "  '''\n",
        "  Input: X and Y are the input training datasets, learning_rate, num_iterations are for gradient descent optimization.\n",
        "  Output: Returns the optimized parameters.\n",
        "  '''\n",
        "  np.random.seed(2)\n",
        "  losses = []# keep track of loss\n",
        "  \n",
        "  # Parameters initialization\n",
        "  parameters = initialize_parameters(dimensions)\n",
        "\n",
        "  for i in range(0, num_iterations):\n",
        "\n",
        "      # Forward propagation\n",
        "      HL, memories = L_layer_forward(X, parameters)\n",
        "      \n",
        "      # Compute loss\n",
        "      loss = compute_loss(HL, Y)\n",
        "  \n",
        "      # Backward propagation\n",
        "      gradients = L_layer_backward(HL, Y, memories)\n",
        "\n",
        "      # Update parameters.\n",
        "      parameters = update_parameters(parameters, gradients, learning_rate)\n",
        "      \n",
        "      # Printing the loss every 100 training example\n",
        "      if print_loss and i % 100 == 0:\n",
        "          print (\"Loss after iteration %i: %f\" %(i, loss))\n",
        "          losses.append(loss)\n",
        "          \n",
        "  # plotting the loss\n",
        "  plt.plot(np.squeeze(losses))\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('iterations (per tens)')\n",
        "  plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "  plt.show()\n",
        "  \n",
        "  return parameters"
      ],
      "metadata": {
        "id": "3tJNXskjfL3-"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set_x_new = train_set_x[:,0:5000]\n",
        "train_set_y_new = train_set_y[:,0:5000]\n",
        "train_set_x_new.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XF8nHnfTfMEH",
        "outputId": "4152d00e-f15f-4f81-98de-dafa4a5db69c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 5000)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = L_layer_model(train_set_x_new, train_set_y_new, dimensions, num_iterations = 2000, print_loss = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "vBH1GTPzgtq6",
        "outputId": "ce99c112-8e69-402a-8c07-7c4f93362527"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss after iteration 0: 2.422624\n",
            "Loss after iteration 100: 2.129232\n",
            "Loss after iteration 200: 1.876095\n",
            "Loss after iteration 300: 1.604213\n",
            "Loss after iteration 400: 1.350205\n",
            "Loss after iteration 500: 1.144823\n",
            "Loss after iteration 600: 0.990554\n",
            "Loss after iteration 700: 0.876603\n",
            "Loss after iteration 800: 0.791154\n",
            "Loss after iteration 900: 0.725441\n",
            "Loss after iteration 1000: 0.673485\n",
            "Loss after iteration 1100: 0.631386\n",
            "Loss after iteration 1200: 0.596598\n",
            "Loss after iteration 1300: 0.567342\n",
            "Loss after iteration 1400: 0.542346\n",
            "Loss after iteration 1500: 0.520746\n",
            "Loss after iteration 1600: 0.501865\n",
            "Loss after iteration 1700: 0.485205\n",
            "Loss after iteration 1800: 0.470368\n",
            "Loss after iteration 1900: 0.457054\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def L_layer_model_L2_regularization(X, Y, dimensions, learning_rate = 0.0075, num_iterations = 3000, print_loss=False, lambdax = 0):\n",
        "  '''\n",
        "  Input: X and Y are the input training datasets, learning_rate, num_iterations are for gradient descent optimization.\n",
        "  Output: Returns the optimized parameters.\n",
        "  '''\n",
        "  np.random.seed(2)\n",
        "  losses = []# keep track of loss\n",
        "  \n",
        "  # Parameters initialization\n",
        "  parameters = initialize_parameters(dimensions)\n",
        "\n",
        "  for i in range(0, num_iterations):\n",
        "\n",
        "      # Forward propagation\n",
        "      HL, memories = L_layer_forward(X, parameters)\n",
        "      \n",
        "      # Compute loss\n",
        "      loss = compute_loss_with_L2(HL, Y, parameters, lambdax)\n",
        "  \n",
        "      # Backward propagation\n",
        "      gradients = L_layer_backward_with_L2(HL, Y, memories, lambdax)\n",
        "\n",
        "      # Update parameters.\n",
        "      parameters = update_parameters(parameters, gradients, learning_rate)\n",
        "      \n",
        "      # Printing the loss every 100 training example\n",
        "      if print_loss and i % 100 == 0:\n",
        "          print (\"Loss after iteration %i: %f\" %(i, loss))\n",
        "          losses.append(loss)\n",
        "          \n",
        "  # plotting the loss\n",
        "  plt.plot(np.squeeze(losses))\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('iterations (per tens)')\n",
        "  plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "  plt.show()\n",
        "  \n",
        "  return parameters"
      ],
      "metadata": {
        "id": "D4Z6HKnrS2de"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = L_layer_model_L2_regularization(train_set_x_new, train_set_y_new, dimensions, num_iterations = 2000, print_loss = True, lambdax = 0.7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "OZSVKbwWSsvj",
        "outputId": "6e554e52-401a-4ecf-ba12-e16161d6399c"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss after iteration 0: 2.447456\n",
            "Loss after iteration 100: 2.154030\n",
            "Loss after iteration 200: 1.900876\n",
            "Loss after iteration 300: 1.629002\n",
            "Loss after iteration 400: 1.375035\n",
            "Loss after iteration 500: 1.169724\n",
            "Loss after iteration 600: 1.015534\n",
            "Loss after iteration 700: 0.901658\n",
            "Loss after iteration 800: 0.816278\n",
            "Loss after iteration 900: 0.750627\n",
            "Loss after iteration 1000: 0.698728\n",
            "Loss after iteration 1100: 0.656680\n",
            "Loss after iteration 1200: 0.621938\n",
            "Loss after iteration 1300: 0.592725\n",
            "Loss after iteration 1400: 0.567769\n",
            "Loss after iteration 1500: 0.546205\n",
            "Loss after iteration 1600: 0.527359\n",
            "Loss after iteration 1700: 0.510731\n",
            "Loss after iteration 1800: 0.495926\n",
            "Loss after iteration 1900: 0.482640\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXwV1fnH8c83CwkkIYEQdsIqIIKCpiB1KW4I1kptreLS2tZKaWtr+7PtT9v+1NrN1tZWu2ipWm3rWpeKC6J1V0QNyL6D7FtYQ4AEQp7fHzPBS7wJgeRmsjzv12temXvOmZnnTpL73NnOkZnhnHPOVZUUdQDOOecaJ08Qzjnn4vIE4ZxzLi5PEM455+LyBOGccy4uTxDOOefi8gThmjVJp0laHHUczjVFniBcwkhaKensKGMwszfNbECUMVSSNErS2gba1lmSFknaI+lVST1raNsrbLMnXObsKvXfk7RRUrGk+ySlheX5kkqqTCbpurB+lKSKKvVXJvadu/rkCcI1aZKSo44BQIFG8f8kqQPwJPB/QHugEHi0hkUeBj4AcoEfA49LygvXdS5wPXAW0BPoA/wUwMxWm1lm5QQMASqAJ2LWvT62jZk9UI9v1SVYo/iDdi2LpCRJ10taLmmrpMcktY+p/3f4jXWnpDckHRdTd7+kuyQ9L2k3cEZ4pPJ9SXPCZR6VlB62P+Rbe01tw/ofStogab2kr4XfiPtV8z5ek/QLSW8De4A+kr4iaaGkXZJWSPp62DYDmAJ0jfk23fVw++IofQ6Yb2b/NrNS4GbgBEkD47yH/sCJwE1mttfMngDmAp8Pm1wJ3Gtm881sO/Az4MvVbPdLwBtmtrKO8btGwhOEi8K3gc8CnwK6AtuBP8fUTwGOAToCM4EHqyx/GfALIAt4Kyy7GBgD9AaOp/oPsWrbShoD/A9wNtAPGFWL9/JFYEIYyypgM3A+0Bb4CvB7SSea2W5gLId+o15fi31xUHhKZ0cN02Vh0+OA2ZXLhdteHpZXdRywwsx2xZTNjml7yLrC+U6ScqvEJoIEUfUIoaOkTZI+lPT7MFG6JiIl6gBcizQRuMbM1gJIuhlYLemLZlZuZvdVNgzrtkvKNrOdYfHTZvZ2OF8afDZxZ/iBi6RngKE1bL+6thcDfzez+THbvvww7+X+yvah52LmX5f0InAaQaKLp8Z9EdvQzFYDOYeJByATKKpStpMgicVruzNO227V1FfOZwFbY8pPBToBj8eULSLYt4sITk89ANwOfL0W78E1An4E4aLQE3iq8psvsBA4QPDNNFnSreEpl2JgZbhMh5jl18RZ58aY+T0EH2zVqa5t1yrrjredqg5pI2mspOmStoXv7TwOjb2qavdFLbZdnRKCI5hYbYFdR9G2an3lfNV1XQk8YWYllQVmttHMFphZhZl9CPyQj05duSbAE4SLwhpgrJnlxEzpZraO4PTROILTPNlAr3AZxSyfqC6INwDdY173qMUyB2MJ7+55Avgt0MnMcoDn+Sj2eHHXtC8OUc1dQ7FT5dHOfOCEmOUygL5heVXzCa6dxB5dnBDT9pB1hfObzOzg0YOk1sAX+PjppaoM/8xpUvyX5RItVVJ6zJQC3A38QuGtl5LyJI0L22cBZQSnL9oAv2zAWB8DviLpWEltCO4COhKtgDSC0zvlksYCo2PqNwG5krJjymraF4eoetdQnKnyWs1TwGBJnw8vwN8IzDGzRXHWuQSYBdwU/n4uJLguU3kn0j+AqyQNkpQD/AS4v8pqLiS4dvJqbKGkMyT1VKAHcCvwdHU7zzU+niBcoj0P7I2ZbgbuACYDL0raBUwHRoTt/0FwsXcdsCCsaxBmNgW4k+CDblnMtstqufwu4DsEiWY7wdHQ5Jj6RQS3lK4ITyl1peZ9cbTvo4jgVM4vwjhGAOMr6yXdLenumEXGAwVh21uBi8J1YGYvAL8h2CerCX43N1XZ5JXAP+3jg8sMA6YBu8Ofcwn2j2si5AMGORefpGOBeUBa1QvGzrUEfgThXAxJF0pKk9QO+DXwjCcH11J5gnDuUF8neJZhOcHdRN+INhznouOnmJxzzsXlRxDOOefialZPUnfo0MF69eoVdRjOOddkzJgxY4uZ5cWra1YJolevXhQWFkYdhnPONRmSVlVXl7BTTJJ6KOhjfoGk+ZKujdNmlIIeNWeF040xdWMkLZa0TNL1iYrTOedcfIk8gigHrjOzmeFj/DMkvWRmC6q0e9PMzo8tUNDH/5+Bc4C1wPuSJsdZ1jnnXIIk7AjCzDaY2cxwfhdBJ2Tdal7qoOHAMjNbYWb7gEcI+udxzjnXQBrkLiZJvQgeu383TvVISbMlTdFHA8N049BeMtdSTXKRNEFSoaTCoqKqPRw755w7WglPEJIyCTr++q6ZFVepngn0NLMTgD8C/znS9ZvZJDMrMLOCvLy4F+Kdc84dhYQmCEmpBMnhQTN7smq9mRVX9h9vZs8T9PzZgaCjttiulruHZc455xpIIu9iEnAvsNDMbq+mTeewHZKGh/FsBd4HjpHUW1Irgt4mJ8dbh3POucRI5F1MpxCM1ztX0qyw7EdAPoCZ3Q1cBHxDUjlBV9Djwy6DyyVdA0wFkoH7qgzrWG/Kyg/wwLSVDMtvxyd61XWseOecaz6aVV9MBQUFdqQPypXuP8AZv32NTm3TeeqbnyQ8oHHOuRZB0gwzK4hX1+L7YkpPTeZ75/Rn1podTJm38fALOOdcC9HiEwTA50/sTv9Omdw2dTH7D1REHY5zzjUKniCA5CTxv2MG8uGW3Tzy3uqow3HOuUbBE0TozIEdGd67PXe8vJSSMh9AzDnnPEGEJHHD2IFsKdnHPW+uiDoc55yLnCeIGMPy23HekM5MemMFRbvKog7HOeci5Qmiih+cO5B95RXc+fLSqENxzrlIeYKooneHDC4dns/D763mwy27ow7HOeci4wkiju+cdQxpKUncNnVR1KE451xkPEHEkZeVxtWn9+H5uRv5YPX2qMNxzrlIeIKoxtdO60OHzFb8asoimlN3JM45V1ueIKqRmZbCtWcdw3sfbuOVRZujDsc55xqcJ4gajB+eT+8OGfz6hUUcqPCjCOdcy+IJogapyUn84NwBLNlUwhMz1kYdjnPONShPEIcxdnBnhvbI4faXlrB334Gow3HOuQbjCeIwKrvg2Fhcyt+nfRh1OM4512ASOeRoD0mvSlogab6ka+O0uVzSHElzJU2TdEJM3cqwfJakIxsFqJ6N6JPLWQM7ctdry9m+e1+UoTjnXINJ5BFEOXCdmQ0CTga+JWlQlTYfAp8ysyHAz4BJVerPMLOh1Y121JD+d+xAdpeV86dXl0UdinPONYiEJQgz22BmM8P5XcBCoFuVNtPMrPJJtOlA90TFU1f9O2Vx0Und+ec7q1izbU/U4TjnXMI1yDUISb2AYcC7NTS7CpgS89qAFyXNkDShhnVPkFQoqbCoqKg+wq3W987pjwS3v7QkodtxzrnGIOEJQlIm8ATwXTMrrqbNGQQJ4n9jik81sxOBsQSnp06Pt6yZTTKzAjMryMvLq+foD9UluzVfOaU3/5m1jvnrdyZ0W845F7WEJghJqQTJ4UEze7KaNscD9wDjzGxrZbmZrQt/bgaeAoYnMtba+saovmS3TuXWKd6Rn3OueUvkXUwC7gUWmtnt1bTJB54EvmhmS2LKMyRlVc4Do4F5iYr1SGS3TuWaM/rx5tItvLV0S9ThOOdcwiTyCOIU4IvAmeGtqrMknSdpoqSJYZsbgVzgL1VuZ+0EvCVpNvAe8JyZvZDAWI/IF0f2pFtOa341ZSEV3gWHc66ZSknUis3sLUCHafM14GtxylcAJ3x8icYhLSWZ75/bn+89Optn5qxn3NBuh1/IOeeaGH+S+iiNO6Ebg7q05bapiykr9y44nHPNjyeIo5SUJK4fO5C12/fyr+mrow7HOefqnSeIOji9fx6n9uvAn15ZSnHp/qjDcc65euUJoo6uHzuQ7Xv28+dXvAsO51zz4gmijgZ3y+bigu7c89aHLNwQ9zlA55xrkjxB1IMbxh5LdutUbnhyro8855xrNjxB1IN2Ga34v/OPZdaaHTz47qqow3HOuXrhCaKefHZoN047pgO/eWExG3eWRh2Oc87VmSeIeiKJn392MPsPVHDz5PlRh+Occ3XmCaIe9czN4Nqzj+GF+Rt5acGmqMNxzrk68QRRz64+rQ8DO2dx49PzKCkrjzoc55w7ap4g6llqchK//NwQNhaX8rsXF0cdjnPOHTVPEAlwYn47rhjRkwemrWTO2h1Rh+Occ0fFE0SC/GDMADpkpnH9E3MpP1ARdTjOOXfEPEEkSNv0VH56wXEs2FDM399eGXU4zjl3xDxBJNCYwZ05+9iO3P7SEtZs2xN1OM45d0QSOeRoD0mvSlogab6ka+O0kaQ7JS2TNEfSiTF1V0paGk5XJirORJLET8cNRoIbn56HmXfD4ZxrOhJ5BFEOXGdmg4CTgW9JGlSlzVjgmHCaANwFIKk9cBMwAhgO3CSpXQJjTZhuOa25bvQAXl1cxHNzN0QdjnPO1VrCEoSZbTCzmeH8LmAhUHVsznHAPywwHciR1AU4F3jJzLaZ2XbgJWBMomJNtC9/shdDumXz02cWsHOvjxvhnGsaGuQahKRewDDg3SpV3YA1Ma/XhmXVlcdb9wRJhZIKi4qK6ivkepWcJH71uSFsLSnj1y8sijoc55yrlYQnCEmZwBPAd82s3gdMMLNJZlZgZgV5eXn1vfp6M7hbNl89pTcPvbua91duizoc55w7rIQmCEmpBMnhQTN7Mk6TdUCPmNfdw7Lqypu0753Tn245rfnRk3PZV+7PRjjnGrdE3sUk4F5goZndXk2zycCXwruZTgZ2mtkGYCowWlK78OL06LCsSctIS+Fnnz2OpZtL+Ovry6MOxznnapSSwHWfAnwRmCtpVlj2IyAfwMzuBp4HzgOWAXuAr4R12yT9DHg/XO4WM2sW52XOHNiJTw/pwh9fXcanj+9Cn7zMqENyzrm41JzuzS8oKLDCwsKowziszcWlnHX76wzums1DV48gONhyzrmGJ2mGmRXEq/MnqSPQsW06/ztmIO+s2MoTM5v8pRXnXDPlCSIilw3P56Se7fjFcwvYtntf1OE459zHeIKISFKS+OWFQ9hVWs7Pn1sQdTjOOfcxniAiNKBzFl//VB+enLmOt5dtiToc55w7hCeIiH37zGPomduGG5+ex34fN8I514h4gohYemoyN54/iOVFu3lg2sqow3HOuYM8QTQCZw7syKgBedzx36UU7SqLOhznnAM8QTQKkvi/8wdRWn6A26Z6Z37OucbBE0Qj0Tcvk6+e0pvHCtcya82OqMNxzjlPEI3JNWf2Iy8rjZsnz6eiovk84e6ca5o8QTQiWempXD9mILPW7ODJD/wJa+dctDxBNDIXDuvGsPwcfv3CInaV+uhzzrnoeIJoZJKSxM2fOY4tJWX86ZVlUYfjnGvBPEE0Qif0yOHik3pw39sfsryoJOpwnHMtlCeIRuoHYwaQnpLMLc8soDl1ye6cazo8QTRSHTLT+O45/Xl9SRGvLNocdTjOuRYokUOO3idps6R51dT/QNKscJon6YCk9mHdSklzw7rGPwJQgnxpZE/6dczklmcXUFZ+IOpwnHMtTCKPIO4HxlRXaWa3mdlQMxsK3AC8XmVY0TPC+rgjHbUEqclJ3PSZQazauod73/ow6nCccy1MwhKEmb0B1HYc6UuBhxMVS1N22jF5jB7UiT+9soyNO0ujDsc514JEfg1CUhuCI40nYooNeFHSDEkTDrP8BEmFkgqLiooSGWpkfvLpQZRXGLdOWRh1KM65FiTyBAF8Bni7yumlU83sRGAs8C1Jp1e3sJlNMrMCMyvIy8tLdKyRyM9tw9dP78N/Zq2ncGVtD8qcc65uGkOCGE+V00tmti78uRl4ChgeQVyNyjdG9aVLdjo3TZ7PAe+nyTnXACJNEJKygU8BT8eUZUjKqpwHRgNx74RqSdq0SuFH5x3L/PXFPPr+mqjDcc61AIm8zfVh4B1ggKS1kq6SNFHSxJhmFwIvmtnumLJOwFuSZgPvAc+Z2QuJirMpOf/4Lgzv3Z7bpi5i5x7vp8k5l1hqTk/pFhQUWGFh835sYsH6Ys7/45t8aWQvbr7guKjDcc41cZJmVPc4QWO4BuGOwKCubbl8RE/+OX0VizYWRx2Oc64Z8wTRBP3POf3JSk/hp5O9nybnXOJ4gmiC2mW04rrRA3hnxVZemLcx6nCcc82UJ4gm6rLh+RzbpS0/f24he/d5P03OufrnCaKJSk4SN39mEOt27OWvbyyPOhznXDPkCaIJG9Enl8+c0JW7XlvO2u17og7HOdfMeIJo4m4YO5AkiVueWRB1KM65ZsYTRBPXNac11559DC8u2MTU+X7B2jlXfzxBNANXndqbgZ2zuHnyfErKyqMOxznXTHiCaAZSk5P45eeGsLG4lN+9uDjqcJxzzYQniGbixPx2XDGiJw9MW8mctTuiDsc51wx4gmhGfjBmAB0y07jhybmUH6iIOhznXBPnCaIZaZueys0XHMf89cXcP21l1OE455o4TxDNzNjBnTlrYEduf2kJ63bsjToc51wT5gmimZHET8cdhxnc+J953pmfc+6oeYJohrq3a8N1o/vz8qLN3pmfc+6oJXJEufskbZYUd7hQSaMk7ZQ0K5xujKkbI2mxpGWSrk9UjM3Zlz/Zi+O6tuWmyfMpLvXR55xzR65WCULStZLaKnCvpJmSRh9msfuBMYdp86aZDQ2nW8JtJQN/BsYCg4BLJQ2qTZzuIynJSfzqc0PYUlLGb6f6sxHOuSNX2yOIr5pZMTAaaAd8Ebi1pgXM7A1g21HENBxYZmYrzGwf8Agw7ijW0+Id3z2HL43sxT+nr+KD1dujDsc518TUNkEo/Hke8E8zmx9TVhcjJc2WNEVS5QDL3YA1MW3WhmXuKHz/3AF0ykrnhifnst+fjXDOHYHaJogZkl4kSBBTJWUBdf20mQn0NLMTgD8C/zmalUiaIKlQUmFRUVEdQ2p+MtNS+Om441i0cRf3vfVh1OE455qQ2iaIq4DrgU+Y2R4gFfhKXTZsZsVmVhLOPw+kSuoArAN6xDTtHpZVt55JZlZgZgV5eXl1CanZOve4zpwzqBO//+8S1mzzcSOcc7VT2wQxElhsZjskXQH8BNhZlw1L6ixJ4fzwMJatwPvAMZJ6S2oFjAcm12VbDn56wXEkS/zEn41wztVSbRPEXcAeSScA1wHLgX/UtICkh4F3gAGS1kq6StJESRPDJhcB8yTNBu4ExlugHLgGmAosBB4Lr3m4Ouia05rrRg/g9SVFPDtnQ9ThOOeaANXm26SkmWZ2Yviswjozu7eyLPEh1l5BQYEVFhZGHUajdaDC+Oyf32bDzlJevu5TZLdOjTok51zEJM0ws4J4dbU9gtgl6QaC21ufk5REcB3CNSHJSeJXnxvCtt1l/PqFRVGH45xr5GqbIC4Bygieh9hIcOH4toRF5RJmcLdsvnpKbx56dzUzVh3NYyrOuZaiVgkiTAoPAtmSzgdKzazGaxCu8freOf3pltOaG56cy75yfzbCORdfbbvauBh4D/gCcDHwrqSLEhmYS5yMtBRuGXccSzaV8Lc3V0QdjnOukUqpZbsfEzwDsRlAUh7wX+DxRAXmEuusYzsxdnBn7nx5Kecf34WeuRlRh+Sca2Rqew0iqTI5hLYewbKukbr5guNITU7yZyOcc3HV9kP+BUlTJX1Z0peB54DnExeWawid2qbzwzEDeHPpFp76oNqH1Z1zLVRtL1L/AJgEHB9Ok8zsfxMZmGsYl4/oSUHPdvzff+axvKgk6nCcc41IrU8TmdkTZvY/4fRUIoNyDSc5SfzxsmGkpyYz8Z8z2F1WHnVIzrlGosYEIWmXpOI40y5JxQ0VpEusLtmtufPSYSwvKuGGJ+f69QjnHHCYBGFmWWbWNs6UZWZtGypIl3in9OvAdaMHMHn2eh6YtjLqcJxzjYDfieQO+san+nL2sZ34+XML/Slr55wnCPeRpCTxu4tPoFu71nzzwZlsKSmLOiTnXIQ8QbhDZLdO5a7LT2LHnv18+6EPKPdhSp1rsTxBuI8Z1LUtv7hwCO+s2MrvXloSdTjOuYh4gnBxXXRSdy4bkc9dry3nxfkbow7HORcBTxCuWjeeP4jju2dz3WOzWblld9ThOOcaWMIShKT7JG2WNK+a+sslzZE0V9K0cDjTyrqVYfksST5EXETSU5P5y+UnkpwsJv5rBnv3HYg6JOdcA0rkEcT9wJga6j8EPmVmQ4CfEXTlEesMMxta3VB4rmF0b9eGO8YPY/GmXfz4KX+IzrmWJGEJwszeAKq9md7MppnZ9vDldIJR6lwj9Kn+eXz3rP48+cE6Hnx3ddThOOcaSGO5BnEVMCXmtQEvSpohaUJNC0qaIKlQUmFRUVFCg2zJvn1mP0YNyOOWZxYwa82OqMNxzjWAyBOEpDMIEkRs77CnmtmJwFjgW5JOr255M5tkZgVmVpCXl5fgaFuupCTxh0uG0rFtGt/81wy27d4XdUjOuQSLNEFIOh64BxhnZlsry81sXfhzM/AUMDyaCF2snDatuOvyk9iyex/XPvIBByr8eoRzzVlkCUJSPvAk8EUzWxJTniEpq3IeGA3EvRPKNbwh3bO55YLjeHPpFu74rz9E51xzVtsxqY+YpIeBUUAHSWuBm4BUADO7G7gRyAX+IgmgPLxjqRPwVFiWAjxkZi8kKk535MYPz2fm6u3c+coyhubncObATlGH5JxLADWn2xYLCgqssNAfm2gIpfsP8Pm7prFm2x6e/fZp5Oe2iTok59xRkDSjuscJIr9I7Zqm9NRk7rr8JAC+8eAMSvf7Q3TONTeeINxRy89tw+8vGcr89cVc99hs9nvPr841K54gXJ2cdWwnfnzesTw3dwPXPDSTfeWeJJxrLjxBuDq7+vQ+3Hj+IKbO38TEf/npJueaC08Qrl589dTe/Pyzg3ll0Wau/kehd+znXDPgCcLVmytO7sltFx3PW8u2cOXf36OkrDzqkJxzdeAJwtWrLxT04A+XDGXGqu186d53KS7dH3VIzrmj5AnC1btxQ7vx58uGMXfdTq6451127PF+m5xrijxBuIQYM7gLd19xEos27GL8pOlsLSmLOiTn3BHyBOES5qxjO3HPlQWs3Lqb8ZOms7m4NOqQnHNHwBOES6jT++fx9y8PZ92OvVwyaTrrd+yNOiTnXC15gnAJN7JvLv+8ajhbdpVx8V/fYc22PVGH5JyrBU8QrkGc1LM9D149gl2l5Vzy13f4cMvuqENyzh2GJwjXYI7vnsNDV4+gtLyCS/76Dks37Yo6JOdcDTxBuAZ1XNdsHplwMgaMnzSdhRuKow7JOVcNTxCuwfXvlMWjE04mNTmJS/82nblrd0YdknMujoQmCEn3SdosKe6QoQrcKWmZpDmSToypu1LS0nC6MpFxuobXJy+Tx74+koxWKVx2z3TeX7kt6pCcc1Uk+gjifmBMDfVjgWPCaQJwF4Ck9gRDlI4AhgM3SWqX0Ehdg8vPbcNjE0eSm9GK8ZOm86dXlnKgovmMcOhcU5fQBGFmbwA1fTUcB/zDAtOBHEldgHOBl8xsm5ltB16i5kTjmqhuOa15+ppTOW9IF3774hIu/dt01vmzEs41ClFfg+gGrIl5vTYsq678YyRNkFQoqbCoqChhgbrEyW6dyp3jh/K7L5zA/HU7GfuHN3h2zvqow3KuxYs6QdSZmU0yswIzK8jLy4s6HHeUJPH5k7rz/LWn0Scvk2se+oDv/3u2dxnuXISiThDrgB4xr7uHZdWVu2auZ24G/544km+f2Y8nZ67l03e+yaw1O6IOy7kWKeoEMRn4Ung308nATjPbAEwFRktqF16cHh2WuRYgNTmJ60YP4JEJIyk/YFx01zT+/Ooyv4DtXANL9G2uDwPvAAMkrZV0laSJkiaGTZ4HVgDLgL8B3wQws23Az4D3w+mWsMy1IMN7t+f5a09jzODO3DZ1MZf9zTv7c64hyaz5fCsrKCiwwsLCqMNw9czMeGLmOm56eh7JSeJXnzueTx/fJeqwnGsWJM0ws4J4dVGfYnLusCRx0Undee47p9E7L5NvPTSTH/x7Nrv9ArZzCeUJwjUZvTpk8PjEkVxzRj8eDy9gz/YL2M4ljCcI16SkJifx/XMH8MjVJ7OvvILP3zWNv7zmF7CdSwRPEK5JGtEnlynXns65gzvzmxcW87m/vM07y7dGHZZzzYonCNdkZbdJ5U+XDuP3l5zA5l1lXPq36Vx533ssWO9diDtXHzxBuCZNEhcO686r3x/Fj84byKw1O/j0H9/ku4984EObOldHfpura1Z27t3P3a8v5+9vf8iBCuPyET255sx+dMhMizo05xqlmm5z9QThmqWNO0u54+UlPFa4lvSUJK4+vQ9fO60PmWkpUYfmXKPiCcK1WMuLSvjt1MVMmbeR3IxWfOesY7h0eD6tUvzsqnPgD8q5FqxvXiZ3XXEST33zkxzTKZObJs/n7Ntf5+lZ66jwW2Odq5EnCNciDMtvx8NXn8z9X/kEGWkpXPvILM7/41u8vqSI5nQU7Vx98gThWgxJjBrQkee+fSp/uGQou8r2c+V973HZ397lvQ+3eaJwrgq/BuFarH3lFTz07ir++Moytu7ex8DOWVx+ck8uHNbNL2a7FsMvUjtXgz37ynlm9nr+8c4q5q8vJqNVMhee2I0rTu7JwM5tow7PuYTyBOFcLZgZs9bs4F/TV/PMnPXsK6/gE73accXJPRkzuDNpKclRh+hcvfME4dwR2r57H/+esYYH313Nqq17yM1oxSWf6MGlw/Pp0b5N1OE5V28iSxCSxgB3AMnAPWZ2a5X63wNnhC/bAB3NLCesOwDMDetWm9kFh9ueJwhX3yoqjDeXbeFf01fx8sJNGHDmgI5ccXJPTu+fR3KSog7RuTqJJEFISgaWAOcAawmGDr3UzBZU0/7bwDAz+2r4usTMMo9km54gXCKt27GXR95bzcPvrWFLSRk92rfmsuE9ubigO7nelYdroqJKECOBm83s3PD1DQBm9n9sYkgAABHASURBVKtq2k8DbjKzl8LXniBco7SvvIIXF2zkn++s4t0Pt9EqOYlzBnVi7JDOnDGgIxl+B5RrQmpKEIn8S+4GrIl5vRYYEa+hpJ5Ab+CVmOJ0SYVAOXCrmf2nmmUnABMA8vPz6yFs52rWKiWJ84/vyvnHd2XJpl08OH0Vz83dwHNzN5CWksSn+ucxdkhnzjq2E23TU6MO17mj1li+6owHHjezAzFlPc1snaQ+wCuS5prZ8qoLmtkkYBIERxANE65zgf6dsvjpuMHc+JnjKFy5jSnzNvLCvI28uGATqcni1H4dGDu4C+cM6kS7jFZRh+vcEUlkglgH9Ih53T0si2c88K3YAjNbF/5cIek1YBjwsQThXGOQnCRG9MllRJ9cbjx/EB+s2cEL8zbw/NyNvLp4DslPiZF9chk7pDOjB3UmL8uvWbjGL5HXIFIILlKfRZAY3gcuM7P5VdoNBF4AelsYjKR2wB4zK5PUAXgHGFfdBe5Kfg3CNTZmxrx1xUyZt4Ep8zby4ZbdJAk+0as9Ywd3ZszgLnTOTo86TNeCRXmb63nAHwhuc73PzH4h6Rag0Mwmh21uBtLN7PqY5T4J/BWoIOgv6g9mdu/htucJwjVmZsbiTbuYMncjU+ZtYMmmEgBOzM/hnEGdObVfBwZ1beu3zroG5Q/KOdcILdtcwgvhkcX8cBzt7NapfLJvLp/s14FT+3WgV24bJE8YLnE8QTjXyG3eVco7y7fy9rItvL1sK+t27AWga3Y6p/TrwKnHdGBk31w6ZvnpKFe/PEE414SYGau27uGtZVt4e9kWpi3fys69+wEY0CmLT/bL5dR+HRjRJ9d7nXV15gnCuSbsQIWxYH0xby3bwrTlW3jvw22UlVeQnCSG9sjhlL65nNwnl+N75HjCcEfME4RzzUjp/gPMXLWdt5dv4a1lW5m7dgcVBkkKnssYlp/DsB7tGJafQ9+8TJL8orergScI55qxnXv388Hq7XywegcfrNnBrNXbKS4tByArLYWh+TkM65HDsPx2DO2R4w/suUNE1dWGc64BZLdOZdSAjowa0BEIeqBdsWU3s9bsOJg4/vTqMirC74K9ctswLL/dwSONgV2ySE320Yfdx/kRhHMtwO6ycuau28kHq3cwa812Zq7eQdGuMgDSUpIY1LUtx3YJpkFdshjQua1fz2gh/BSTc+4QZsb6naUHjzDmrdvJwg3FB09NAfTMbcOxnSsTRxbHdmlL93at/bmMZsZPMTnnDiGJbjmt6ZbTmvOP7wp8lDQWri9mwYZiFobT1AUbqfwemZWeEiaNrINHHAM6Z5Ge6sOxNkeeIJxzwKFJ4+xBnQ6W7y4rZ9HGXSzaWJk0dvH4jLXs3hd0vpwk6JWbQZ+8TPp2zKBvXiZ98zLpl5dJdhvv7rwp8wThnKtRRloKJ/Vsx0k92x0sq6gw1mzfw8INxSzYsIulm3axvKiEN5YUse9AxcF2HTLT6JuXQd+OmWHiCBJIt5zWfvttE+AJwjl3xJKSRM/cDHrmZjBmcJeD5eUHKli7fS/Li0pYXlTCss0lLC/azXNzNhx8GhwgPTWJ3h0y6dcxSBq9O2SQ374NPXMzaNcm1a9zNBKeIJxz9SYlOYleHTLo1SGDs4796DSVmbFt9z6WF+0OksfmIIHMXrODZ+esJ/Zemay0FHq0b0PP3Dbk57YJEkf7DHrmtqFLdjopfktug/EE4ZxLOEnkZqaRm5nG8N7tD6kr3X+A1dv2sGrrHlZv28PqrbtZtW0Pizft4uWFmw85ZZWSJLq1a01++zBx5LYhv30GPdq3pntOG9q2TvGjj3rkCcI5F6n01GT6d8qif6esj9UdqDA2FpeyeuseVm/b/VES2baHZ6uctgLIaJVM15zWdM1pTbd2wQX3rjnpdMtpQ9ecdDq1TfeHAo+AJwjnXKOVnPTRnVUj++Z+rH7nnv2s3raHtdv3sG7HXtbt2Mv68OfcdTvZtnvfIe2TBJ3bph9MIpWJpGt2kDw6tU0nN6OVX0APJTRBSBoD3EEwotw9ZnZrlfovA7fx0VjVfzKze8K6K4GfhOU/N7MHEhmrc67pyW6TypA22Qzpnh23fu++AweTRuW0Nvw5a80OpszbwP4Dhz4snJosOmal07FtGp3DpNE5O51ObdOC+bAsowU8aZ6wdygpGfgzcA6wFnhf0uQ440o/ambXVFm2PXATUAAYMCNcdnui4nXONT+tWyXTr2Nwt1Q8ByqMLSVlrN+xl03FpWwqLmNjcSmbdpayaVcpSzbt4s2lWygpK//YsllpKXTKDhJGx7Zp5GWlkZdZ5WdWGtmtm+5dWYlMgcOBZWa2AkDSI8A4oGqCiOdc4CUz2xYu+xIwBng4QbE651qg5CQdPLVUk5Ky8iCB7CwNEkhxGZuKS9kYJpJ3V+ymqKSMfeUVH1s2NVl0qJI4OsQkkMrX7TNa0Ta9cV1kT2SC6AasiXm9FhgRp93nJZ0OLAG+Z2Zrqlm2W7yNSJoATADIz8+vh7Cdc+5QmWkpZIZPiFfHzCguLadoV1kwlQQ/t4Q/i3aVsWFnKXPW7WRrSdnB3nVjpSaL9hmtaJ+RRm5GK3IzW9E+o1U4HySRDplBfUMklKhPoj0DPGxmZZK+DjwAnHkkKzCzScAkCDrrq/8QnXPu8CSR3TqV7Nap1Z7SqnSgwti+Z9/BxLGlpIxtu/expWQf23Z/NL962x627d4X9xQXfJRQ8tu34d8TP1nv7ymRCWId0CPmdXc+uhgNgJltjXl5D/CbmGVHVVn2tXqP0DnnIpCcFJx26pCZxrFdDt++dP8Btu3eFyaOspj5IKEkJegoIpEJ4n3gGEm9CT7wxwOXxTaQ1MXMNoQvLwAWhvNTgV9Kquz8ZTRwQwJjdc65Ris99aPnOxpSwhKEmZVLuobgwz4ZuM/M5ku6BSg0s8nAdyRdAJQD24Avh8tuk/QzgiQDcEvlBWvnnHMNwwcMcs65FqymAYP8mXPnnHNxeYJwzjkXlycI55xzcXmCcM45F5cnCOecc3F5gnDOORdXs7rNVVIRsOooF+8AbKnHcOqbx1c3Hl/deHx105jj62lmefEqmlWCqAtJhdXdC9wYeHx14/HVjcdXN409vur4KSbnnHNxeYJwzjkXlyeIj0yKOoDD8PjqxuOrG4+vbhp7fHH5NQjnnHNx+RGEc865uDxBOOeci6vFJQhJYyQtlrRM0vVx6tMkPRrWvyupVwPG1kPSq5IWSJov6do4bUZJ2ilpVjjd2FDxhdtfKWluuO2P9a2uwJ3h/psj6cQGjG1AzH6ZJalY0nertGnQ/SfpPkmbJc2LKWsv6SVJS8Of7apZ9sqwzVJJVzZgfLdJWhT+/p6SlFPNsjX+LSQwvpslrYv5HZ5XzbI1/q8nML5HY2JbKWlWNcsmfP/VmZm1mIlg4KLlQB+gFTAbGFSlzTeBu8P58cCjDRhfF+DEcD4LWBInvlHAsxHuw5VAhxrqzwOmAAJOBt6N8He9keAhoMj2H3A6cCIwL6bsN8D14fz1wK/jLNceWBH+bBfOt2ug+EYDKeH8r+PFV5u/hQTGdzPw/Vr8/mv8X09UfFXqfwfcGNX+q+vU0o4ghgPLzGyFme0DHgHGVWkzDnggnH8cOEtK0ICvVZjZBjObGc7vIhiCtVtDbLsejQP+YYHpQI6kWoy6W+/OApab2dE+WV8vzOwNgtESY8X+jT0AfDbOoucCL5nZNjPbDrwEjGmI+MzsRTMrD19OJxgTPhLV7L/aqM3/ep3VFF/4uXEx8HB9b7ehtLQE0Q1YE/N6LR//AD7YJvwn2QnkNkh0McJTW8OAd+NUj5Q0W9IUScc1aGBgwIuSZkiaEKe+Nvu4IYyn+n/MKPcfQCf7aCz2jUCnOG0ay378KsERYTyH+1tIpGvCU2D3VXOKrjHsv9OATWa2tJr6KPdfrbS0BNEkSMoEngC+a2bFVapnEpw2OQH4I/CfBg7vVDM7ERgLfEvS6Q28/cOS1Aq4APh3nOqo998hLDjX0CjvNZf0Y4Lx4h+spklUfwt3AX2BocAGgtM4jdGl1Hz00Oj/l1paglgH9Ih53T0si9tGUgqQDWxtkOiCbaYSJIcHzezJqvVmVmxmJeH880CqpA4NFZ+ZrQt/bgaeIjiUj1WbfZxoY4GZZrapakXU+y+0qfK0W/hzc5w2ke5HSV8GzgcuD5PYx9TibyEhzGyTmR0wswrgb9VsN+r9lwJ8Dni0ujZR7b8j0dISxPvAMZJ6h98yxwOTq7SZDFTeMXIR8Ep1/yD1LTxneS+w0Mxur6ZN58prIpKGE/wOGySBScqQlFU5T3Axc16VZpOBL4V3M50M7Iw5ndJQqv3mFuX+ixH7N3Yl8HScNlOB0ZLahadQRodlCSdpDPBD4AIz21NNm9r8LSQqvthrWhdWs93a/K8n0tnAIjNbG68yyv13RKK+St7QE8FdNksI7nD4cVh2C8E/A0A6wamJZcB7QJ8GjO1UgtMNc4BZ4XQeMBGYGLa5BphPcFfGdOCTDRhfn3C7s8MYKvdfbHwC/hzu37lAQQP/fjMIPvCzY8oi238EiWoDsJ/gPPhVBNe0XgaWAv8F2odtC4B7Ypb9avh3uAz4SgPGt4zg/H3l32DlXX1dgedr+ltooPj+Gf5tzSH40O9SNb7w9cf+1xsivrD8/sq/uZi2Db7/6jp5VxvOOefiammnmJxzztWSJwjnnHNxeYJwzjkXlycI55xzcXmCcM45F5cnCNfoSZoW/uwl6bJ6XveP4m0rUSR9NlE9yFZ9L/W0ziGS7q/v9bqmwW9zdU2GpFEEvXiefwTLpNhHHc/Fqy8xs8z6iK+W8UwjeOZmSx3X87H3laj3Ium/wFfNbHV9r9s1bn4E4Ro9SSXh7K3AaWH/+d+TlByOXfB+2HHb18P2oyS9KWkysCAs+0/YKdr8yo7RJN0KtA7X92DstsInwW+TNC/ss/+SmHW/JulxBWMmPBjzZPatCsbymCPpt3HeR3+grDI5SLpf0t2SCiUtkXR+WF7r9xWz7njv5QpJ74Vlf5WUXPkeJf1CQYeF0yV1Csu/EL7f2ZLeiFn9MwRPIruWJuon9Xzy6XATUBL+HEXMWA7ABOAn4XwaUAj0DtvtBnrHtK18Wrk1QZcGubHrjrOtzxN0sZ1M0NvqaoLxOkYR9PDbneAL1jsET8DnAov56Kg8J877+Arwu5jX9wMvhOs5huBJ3PQjeV/xYg/njyX4YE8NX/8F+FI4b8BnwvnfxGxrLtCtavzAKcAzUf8d+NTwU0ptE4lzjdBo4HhJF4Wvswk+aPcB75nZhzFtvyPpwnC+R9iupj6YTgUeNrMDBJ3rvQ58AigO170WQMFoYb0Iuu0oBe6V9CzwbJx1dgGKqpQ9ZkGnc0slrQAGHuH7qs5ZwEnA++EBTms+6hRwX0x8M4Bzwvm3gfslPQbEdhS5maCbCNfCeIJwTZmAb5vZIZ3Yhdcqdld5fTYw0sz2SHqN4Jv60SqLmT9AMPpaedj531kEnTxeA5xZZbm9BB/2sapeBDRq+b4OQ8ADZnZDnLr9Zla53QOEnwNmNlHSCODTwAxJJ5nZVoJ9tbeW23XNiF+DcE3JLoKhWCtNBb6hoIt0JPUPe8asKhvYHiaHgQRDoVbaX7l8FW8Cl4TXA/IIhpZ8r7rAFIzhkW1BF+LfA06I02wh0K9K2RckJUnqS9CB2+IjeF9Vxb6Xl4GLJHUM19FeUs+aFpbU18zeNbMbCY50KrvL7k9j7GnUJZwfQbimZA5wQNJsgvP3dxCc3pkZXiguIv7wnS8AEyUtJPgAnh5TNwmYI2mmmV0eU/4UMJKgt00DfmhmG8MEE08W8LSkdIJv7/8Tp80bwO8kKeYb/GqCxNOWoPfPUkn31PJ9VXXIe5H0E4IRy5IIehv9FlDTEKy3STomjP/l8L0DnAE8V4vtu2bGb3N1rgFJuoPggu9/w+cLnjWzxyMOq1qS0oDXCUY/q/Z2Ydc8+Skm5xrWL4E2UQdxBPKB6z05tEx+BOGccy4uP4JwzjkXlycI55xzcXmCcM45F5cnCOecc3F5gnDOORfX/wO/qg/g1j78JgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, y, parameters):\n",
        "  '''\n",
        "  Input: Input data X, y, optimized parameters\n",
        "  Output: returns the predicitons\n",
        "  '''\n",
        "  m = X.shape[1]\n",
        "  n = len(parameters) // 2 # number of layers in the neural network\n",
        "  \n",
        "  # Forward propagation\n",
        "  probas, caches = L_layer_forward(X, parameters)\n",
        "  \n",
        "  p = np.argmax(probas, axis = 0)\n",
        "  act = np.argmax(y, axis = 0)\n",
        "\n",
        "  print(\"Accuracy: \"  + str(np.sum((p == act)/m)))\n",
        "      \n",
        "  return p"
      ],
      "metadata": {
        "id": "jJ2y-zG3gtul"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train set predictions\n",
        "pred_train = predict(train_set_x_new, train_set_y_new, parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ji4eRknQgtws",
        "outputId": "9005cc34-10ba-446c-a068-fd6d5b7c2d5c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8774000000000002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test set predicitons\n",
        "pred_test = predict(test_set_x, test_set_y, parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41IkJb-1iTtA",
        "outputId": "3323874c-2fd4-4e9c-97d8-bb99122368aa"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8674000000000002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the true labels Images and prediction\n",
        "index  = 3474\n",
        "k = test_set_x[:,index]\n",
        "k = k.reshape((28, 28))\n",
        "plt.title('Label is {label}'.format(label=(pred_test[index], np.argmax(test_set_y, axis = 0)[index])))\n",
        "plt.imshow(k, cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "cdB_00qwiTx3",
        "outputId": "111712e8-86d1-4dfc-f737-8ff70c76baaf"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f4e1b7c9b50>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iBhmpbfmkTA9"
      },
      "execution_count": 48,
      "outputs": []
    }
  ]
}